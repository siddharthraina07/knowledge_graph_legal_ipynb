{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-07-16T06:42:05.647935Z","iopub.status.busy":"2024-07-16T06:42:05.647151Z","iopub.status.idle":"2024-07-16T06:42:24.052559Z","shell.execute_reply":"2024-07-16T06:42:24.051464Z","shell.execute_reply.started":"2024-07-16T06:42:05.647904Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting langchain_community\n","  Downloading langchain_community-0.2.7-py3-none-any.whl.metadata (2.5 kB)\n","Requirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (6.0.1)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (2.0.25)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (3.9.1)\n","Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (0.6.7)\n","Collecting langchain<0.3.0,>=0.2.7 (from langchain_community)\n","  Downloading langchain-0.2.8-py3-none-any.whl.metadata (6.9 kB)\n","Collecting langchain-core<0.3.0,>=0.2.12 (from langchain_community)\n","  Downloading langchain_core-0.2.19-py3-none-any.whl.metadata (6.0 kB)\n","Collecting langsmith<0.2.0,>=0.1.0 (from langchain_community)\n","  Downloading langsmith-0.1.86-py3-none-any.whl.metadata (13 kB)\n","Requirement already satisfied: numpy<2,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (1.26.4)\n","Requirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (2.32.3)\n","Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (8.2.3)\n","Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (23.2.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.0.4)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.9.3)\n","Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.3)\n","Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.21.3)\n","Requirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n","Collecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain<0.3.0,>=0.2.7->langchain_community)\n","  Downloading langchain_text_splitters-0.2.2-py3-none-any.whl.metadata (2.1 kB)\n","Requirement already satisfied: pydantic<3,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain<0.3.0,>=0.2.7->langchain_community) (2.5.3)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.12->langchain_community) (1.33)\n","Collecting packaging<25,>=23.2 (from langchain-core<0.3.0,>=0.2.12->langchain_community)\n","  Downloading packaging-24.1-py3-none-any.whl.metadata (3.2 kB)\n","Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.0->langchain_community)\n","  Downloading orjson-3.10.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain_community) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain_community) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain_community) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain_community) (2024.7.4)\n","Requirement already satisfied: typing-extensions>=4.6.0 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain_community) (4.9.0)\n","Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.0.3)\n","Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.12->langchain_community) (2.4)\n","Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.7->langchain_community) (0.6.0)\n","Requirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.7->langchain_community) (2.14.6)\n","Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n","Downloading langchain_community-0.2.7-py3-none-any.whl (2.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading langchain-0.2.8-py3-none-any.whl (987 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m987.6/987.6 kB\u001b[0m \u001b[31m45.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading langchain_core-0.2.19-py3-none-any.whl (366 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m366.5/366.5 kB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading langsmith-0.1.86-py3-none-any.whl (129 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.4/129.4 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading langchain_text_splitters-0.2.2-py3-none-any.whl (25 kB)\n","Downloading orjson-3.10.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading packaging-24.1-py3-none-any.whl (53 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: packaging, orjson, langsmith, langchain-core, langchain-text-splitters, langchain, langchain_community\n","  Attempting uninstall: packaging\n","    Found existing installation: packaging 21.3\n","    Uninstalling packaging-21.3:\n","      Successfully uninstalled packaging-21.3\n","  Attempting uninstall: orjson\n","    Found existing installation: orjson 3.9.10\n","    Uninstalling orjson-3.9.10:\n","      Successfully uninstalled orjson-3.9.10\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","cudf 24.6.1 requires cubinlinker, which is not installed.\n","cudf 24.6.1 requires cupy-cuda11x>=12.0.0, which is not installed.\n","cudf 24.6.1 requires ptxcompiler, which is not installed.\n","cuml 24.6.1 requires cupy-cuda11x>=12.0.0, which is not installed.\n","dask-cudf 24.6.1 requires cupy-cuda11x>=12.0.0, which is not installed.\n","keras-cv 0.9.0 requires keras-core, which is not installed.\n","tensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\n","apache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.8 which is incompatible.\n","apache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.4 which is incompatible.\n","apache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 16.1.0 which is incompatible.\n","cudf 24.6.1 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.5.0 which is incompatible.\n","distributed 2024.5.1 requires dask==2024.5.1, but you have dask 2024.7.0 which is incompatible.\n","google-cloud-bigquery 2.34.4 requires packaging<22.0dev,>=14.3, but you have packaging 24.1 which is incompatible.\n","jupyterlab 4.2.3 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\n","jupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\n","libpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\n","momepy 0.7.2 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\n","osmnx 1.9.3 requires shapely>=2.0, but you have shapely 1.8.5.post1 which is incompatible.\n","pointpats 2.5.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\n","rapids-dask-dependency 24.6.0a0 requires dask==2024.5.1, but you have dask 2024.7.0 which is incompatible.\n","spaghetti 1.7.6 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\n","spopt 0.6.1 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\n","tensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.4.1 which is incompatible.\n","ydata-profiling 4.6.4 requires numpy<1.26,>=1.16.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed langchain-0.2.8 langchain-core-0.2.19 langchain-text-splitters-0.2.2 langchain_community-0.2.7 langsmith-0.1.86 orjson-3.10.6 packaging-24.1\n"]}],"source":["!pip install langchain_community"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-07-16T06:42:24.054933Z","iopub.status.busy":"2024-07-16T06:42:24.054648Z","iopub.status.idle":"2024-07-16T06:42:37.164056Z","shell.execute_reply":"2024-07-16T06:42:37.163151Z","shell.execute_reply.started":"2024-07-16T06:42:24.054909Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting PyPDF2\n","  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n","Requirement already satisfied: langchain in /opt/conda/lib/python3.10/site-packages (0.2.8)\n","Collecting langchain_groq\n","  Downloading langchain_groq-0.1.6-py3-none-any.whl.metadata (2.8 kB)\n","Requirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (6.0.1)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.0.25)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (3.9.1)\n","Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (4.0.3)\n","Requirement already satisfied: langchain-core<0.3.0,>=0.2.19 in /opt/conda/lib/python3.10/site-packages (from langchain) (0.2.19)\n","Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (0.2.2)\n","Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /opt/conda/lib/python3.10/site-packages (from langchain) (0.1.86)\n","Requirement already satisfied: numpy<2,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain) (1.26.4)\n","Requirement already satisfied: pydantic<3,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.5.3)\n","Requirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.32.3)\n","Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (8.2.3)\n","Collecting groq<1,>=0.4.1 (from langchain_groq)\n","  Downloading groq-0.9.0-py3-none-any.whl.metadata (13 kB)\n","Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.3)\n","Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /opt/conda/lib/python3.10/site-packages (from groq<1,>=0.4.1->langchain_groq) (4.2.0)\n","Requirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from groq<1,>=0.4.1->langchain_groq) (1.9.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from groq<1,>=0.4.1->langchain_groq) (0.27.0)\n","Requirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from groq<1,>=0.4.1->langchain_groq) (1.3.0)\n","Requirement already satisfied: typing-extensions<5,>=4.7 in /opt/conda/lib/python3.10/site-packages (from groq<1,>=0.4.1->langchain_groq) (4.9.0)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.19->langchain) (1.33)\n","Requirement already satisfied: packaging<25,>=23.2 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.19->langchain) (24.1)\n","Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.6)\n","Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (0.6.0)\n","Requirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (2.14.6)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2024.7.4)\n","Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n","Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->groq<1,>=0.4.1->langchain_groq) (1.2.0)\n","Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq) (1.0.5)\n","Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq) (0.14.0)\n","Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.19->langchain) (2.4)\n","Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","\u001b[?25hDownloading langchain_groq-0.1.6-py3-none-any.whl (14 kB)\n","Downloading groq-0.9.0-py3-none-any.whl (103 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.5/103.5 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: PyPDF2, groq, langchain_groq\n","Successfully installed PyPDF2-3.0.1 groq-0.9.0 langchain_groq-0.1.6\n"]}],"source":["!pip install PyPDF2 langchain langchain_groq"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-07-16T06:42:37.165977Z","iopub.status.busy":"2024-07-16T06:42:37.165597Z","iopub.status.idle":"2024-07-16T06:42:49.151488Z","shell.execute_reply":"2024-07-16T06:42:49.150341Z","shell.execute_reply.started":"2024-07-16T06:42:37.165939Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: PyPDF2 in /opt/conda/lib/python3.10/site-packages (3.0.1)\n"]}],"source":["!  pip install PyPDF2"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-07-16T06:42:49.154326Z","iopub.status.busy":"2024-07-16T06:42:49.154019Z","iopub.status.idle":"2024-07-16T06:42:51.661341Z","shell.execute_reply":"2024-07-16T06:42:51.660461Z","shell.execute_reply.started":"2024-07-16T06:42:49.154299Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: langchain in /opt/conda/lib/python3.10/site-packages (0.2.8)\n","Requirement already satisfied: langchain_community in /opt/conda/lib/python3.10/site-packages (0.2.7)\n","Requirement already satisfied: langchain_groq in /opt/conda/lib/python3.10/site-packages (0.1.6)\n","Requirement already satisfied: PyPDF2 in /opt/conda/lib/python3.10/site-packages (3.0.1)\n","\u001b[31mERROR: Could not find a version that satisfies the requirement concurrent (from versions: none)\u001b[0m\u001b[31m\n","\u001b[0m\u001b[31mERROR: No matching distribution found for concurrent\u001b[0m\u001b[31m\n","\u001b[0m"]}],"source":["!pip install  langchain langchain_community langchain_groq PyPDF2 concurrent"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-07-16T07:28:28.510324Z","iopub.status.busy":"2024-07-16T07:28:28.509691Z","iopub.status.idle":"2024-07-16T07:28:42.525572Z","shell.execute_reply":"2024-07-16T07:28:42.524570Z","shell.execute_reply.started":"2024-07-16T07:28:28.510292Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting PyMuPDF\n","  Downloading PyMuPDF-1.24.7-cp310-none-manylinux2014_x86_64.whl.metadata (3.4 kB)\n","Collecting PyMuPDFb==1.24.6 (from PyMuPDF)\n","  Downloading PyMuPDFb-1.24.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.4 kB)\n","Downloading PyMuPDF-1.24.7-cp310-none-manylinux2014_x86_64.whl (3.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading PyMuPDFb-1.24.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (15.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.7/15.7 MB\u001b[0m \u001b[31m77.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hInstalling collected packages: PyMuPDFb, PyMuPDF\n","Successfully installed PyMuPDF-1.24.7 PyMuPDFb-1.24.6\n"]}],"source":["!pip install PyMuPDF"]},{"cell_type":"code","execution_count":44,"metadata":{"execution":{"iopub.execute_input":"2024-07-16T08:03:57.893463Z","iopub.status.busy":"2024-07-16T08:03:57.892980Z","iopub.status.idle":"2024-07-16T08:04:01.972124Z","shell.execute_reply":"2024-07-16T08:04:01.971211Z","shell.execute_reply.started":"2024-07-16T08:03:57.893426Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Restored Content: Here is the restored content of the document:\n","\n","**IN THE HIGH COURT OF MADHYA PRADESH PRINCIPAL SEAT AT JABALPUR**\n","\n","**WRIT PETITION NO. & GP/024**\n","\n","**PETITIONER**\n","\n","Sanjeev Kumar Sahu, S/o Late Shri Sevakram Sahu, Aged about 30 years, Occupation-Business, R/o Ward no.13, Nandani Nagar, Near Sai Gate, Bhopal Sagar main road, Gairatganj, Raisen, District-Raisen (M.P.).\n","\n","**RESPONDENTS**\n","\n","1. State of Madhya Pradesh, Through its Principal Secretary, Energy Department, Vallabh Bhawan, Bhopal, District-Bhopal (M.P.).\n","2. Madhya Pradesh Madhya Khetra Vidyut Vitran Company Limited, through its Managing Director, Nishtha Parisar, Govindpura, Bhopal (M.P.).\n","3. Collector, Raisen, District Raisen (M.P.).\n","4. Chief Engineer, Madhya Pradesh Madhya Khetra Vidyut Vitran Company Limited, Raisen, District-Raisen (M.P.).\n","5. Executive Engineer, Madhya Pradesh Madhya Khetra Vidyut Vitran Company Limited, Raisen, District-Raisen (M.P.).\n","6. Junior Engineer, Madhya Pradesh Madhya Khetra Vidyut Vitran Company Limited, Raisen, District-Raisen (M.P.).\n","\n","**WRIT PETITION UNDER ARTICLE 226 OF THE CONSTITUTION OF INDIA**\n","\n","**PARTICULARS OF THE CAUSE/OBJECT AGAINST WHICH THE PETITION IS BEING MADE**\n","\n","The Petitioner is challenging the inaction of respondents no.3 to 6 with regards to the request of the Petitioner for shifting of electricity transformer installed near his shop.\n","\n","**FACTS OF THE CASE**\n","\n","1. The Petitioner is a citizen of India and is entitled to protection of his fundamental rights as enshrined in the Constitution of India.\n","2. The Petitioner is a small businessman operating a mobile and hardware shop situated at Ward no.13, Nandani Nagar, Near Sai Mandir Gate, Bhopal Sagar road, District-Raisen (M.P.).\n","3. At around 15 feet of east side of the aforesaid shop, an electricity transformer had been installed by the respondent M.P.M.K.V.V. Com. Ltd.\n","4. On 12.03.2009, the said transformer was caught on fire and the shop of the Petitioner and other relevant articles were turned into ashes.\n","5. The Petitioner had made a police complaint before the local police station P.S. Gairatganj, Raisen, a copy of which is annexed as Annexure P/1.\n","6. As of present scenario, the state government has proposed to construct a four-lane road under the city development programme and as such, the alleged transformer is proposed to be installed besides the shop of the Petitioner.\n","\n","**GROUNDS URGED**\n","\n","The Petitioner urges the following grounds for seeking the kind indulgence of this Hon'ble Court:\n","\n","1. The inaction of respondents no.3 to 6 is illegal, arbitrary, and amounts to life-threatening for the Petitioner, his family, and business.\n","2. On an earlier occasion due to the fire in the alleged transformer, the Petitioner had sustained a loss of around 5 lacs. The life and safety of the Petitioner is in danger if the transformer would be installed besides the shop of the Petitioner.\n","3. The Petitioner is doing his business under threat, and the state agencies are acting spontaneously. Thus, on this ground alone, this is a fit case for interference by this Hon'ble Court.\n","\n","**RELIEF PRAYED FOR**\n","\n","The Petitioner prays that this Hon'ble Court be pleased to:\n","\n","1. Issue a writ in the nature of mandamus for direction of respondent no.3 to 6 to look into the grievance of the Petitioner and take appropriate steps for shifting/installation of electricity transformer to some safer place, far from the shop of the Petitioner, and also take suitable steps which are essential for protection of the life and business of the Petitioner.\n","2. Direct the respondents no.3 and 6 to decide the claim of the Petitioner in respect of loss caused to his shop due to the caught-on-fire of the alleged transformer, accordingly, they may be directed to pay compensation amounting to Rs. 5,00,000/- with suitable interest to the Petitioner.\n","3. Call for the relevant records from the respondents for kind perusal of this Hon'ble Court.\n","4. Any other relief deemed fit on facts and circumstances of the instant case.\n","\n","**INTERIM ORDER/WRIT, IF PRAYED FOR**\n","\n","In view of the facts and circumstances as stated above, as an interim measure, the respondents no.4 to 6 be restrained from installing the electricity transformer besides the shop of the Petitioner and they may be directed to maintain the status quo till the pendency of the present petition.\n","\n","**DOCUMENTS RELIED ON BUT NOT IN POSSESSION OF THE PETITIONER**\n","\n","N.A.\n","\n","**CAVEAT**\n","\n","That no notice of lodging a caveat by the opposite party is received.\n","\n","**PLACE**: JABALPUR (M.P.)\n","**DATED**: 02-06-2024\n","**COUNSEL FOR THE PETITIONER**\n","\n","**AFFIDAVIT**\n","\n","I, Sanjeev Kumar Sahu, S/o Late Shri Sevakram Sahu, Aged about 30 years, Occupation-Business, R/o Ward no.13, Nandani Nagar, Near Sai Gate, Bhopal Sagar main road, Gairatganj, Raisen, District-Raisen (M.P.), do solemnly affirm on oath as under:\n","\n","1. That I am the Petitioner in the instant writ petition as such well conversant with the facts of the instant case.\n","2. That the instant petition has been drafted as per my instructions by my counsel and the contents of the petition from Para 1 to 10 are true and correct to the best of my knowledge.\n","3. That the contents of Para 1 to 10 of accompanying Writ Petition are true and correct to my personal knowledge and belief. The legal averments are based on advice tendered by my Counsel. The copies hereto are true copies of originals.\n","\n","**VERIFICATION**\n","\n","I, the above-named deponent, do hereby verify that the contents of Para's 1 to 3 of the affidavit are true and correct to the best of my knowledge.\n","\n","**VERIFIED AND SIGNED ON**\n","\n","06-06-2024, at Jabalpur (M.P.).\n"]}],"source":["import os\n","import tempfile\n","from pydantic import BaseModel\n","from langchain_community.document_loaders import TextLoader, PyMuPDFLoader\n","from langchain.prompts import PromptTemplate\n","from langchain.chains import LLMChain\n","from langchain_groq import ChatGroq\n","\n","# class DocumentClassificationResponse(BaseModel):\n","#     \"\"\"\n","#     A Pydantic model to structure the response for document classification and restoration.\n","#     \"\"\"\n","#     file_type: str\n","#     restored_content: str\n","\n","# class DocumentSummarizationResponse(BaseModel):\n","#     \"\"\"\n","#     A Pydantic model to structure the response for document summarization.\n","#     \"\"\"\n","#     file_type: str\n","#     summary: str\n","\n","class DocumentProcessor:\n","    \"\"\"\n","    A class to handle document loading, classification, restoration, and summarization using language models.\n","    \"\"\"\n","\n","    def __init__(self):\n","        \"\"\"\n","        Initializes the DocumentProcessor with necessary configurations.\n","        \"\"\"\n","        self.llm = ChatGroq(model_name=\"Llama3-8b-8192\", api_key=\"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\")\n","        self.classification_template = PromptTemplate.from_template(self._get_classification_template())\n","        self.restoration_template = PromptTemplate.from_template(self._get_restoration_template())\n","        self.summary_template = PromptTemplate.from_template(self._get_summary_template())\n","        self.classification_chain = LLMChain(llm=self.llm, prompt=self.classification_template)\n","        self.restoration_chain = LLMChain(llm=self.llm, prompt=self.restoration_template)\n","        self.summary_chain = LLMChain(llm=self.llm, prompt=self.summary_template)\n","\n","    @staticmethod\n","    def _get_classification_template():\n","        \"\"\"\n","        Returns the classification template for the LLM.\n","\n","        Returns:\n","            str: The template string for document classification.\n","        \"\"\"\n","        return \"\"\"<s>[INST] The following is an article:\n","        {text}\n","        Based on this, please classify the document into one of the following categories: Civil, Criminal, Writ.\n","        You can use below paragraph for classification of the document: \n","        \"Civil cases involve disputes between individuals, organizations, or the government, seeking legal remedies like compensation for issues such as contract disputes, torts, family law matters, property disputes, and employment issues.\n","        Criminal cases are offenses against the state or public, with the government prosecuting individuals or entities for crimes like felonies (murder, robbery), misdemeanors (petty theft), and infractions (traffic violations), aiming to punish and deter criminal behavior. \n","        Writ cases involve judicial orders to correct legal errors or enforce rights, with common writs including habeas corpus (ensuring lawful detention), mandamus (ordering a public official to perform a duty), prohibition (stopping a lower court from exceeding its jurisdiction), certiorari (reviewing a lower court's decision), and quo warranto (challenging the right to hold public office).\"\n","        Answer with the category only and nothing else:  [/INST] </s>\"\"\"\n","\n","    @staticmethod\n","    def _get_restoration_template():\n","        \"\"\"\n","        Returns the restoration template for the LLM.\n","\n","        Returns:\n","            str: The template string for document restoration.\n","        \"\"\"\n","        return \"\"\"<s>[INST] The following is an article:\n","        {text}\n","        Based on this, please restore the content of the document by removing anomalous characters and gibberish to produce comprehensible content with proper grammar. \n","        Answer:  [/INST] </s>\"\"\"\n","\n","    @staticmethod\n","    def _get_summary_template():\n","        \"\"\"\n","        Returns the summary template for the LLM.\n","\n","        Returns:\n","            str: The template string for document summarization.\n","        \"\"\"\n","        return \"\"\"<s>[INST] The following is an article:\n","        {text}\n","        Based on this, please provide a summary. \n","        Answer:  [/INST] </s>\"\"\"\n","\n","    def load_documents(self, file_path):\n","        \"\"\"\n","        Loads documents from the given file path.\n","\n","        Args:\n","            file_path (str): The path to the file to be loaded.\n","\n","        Returns:\n","            list: A list of document objects.\n","\n","        Raises:\n","            ValueError: If the file format is unsupported.\n","        \"\"\"\n","        if file_path.lower().endswith('.pdf'):\n","            loader = PyMuPDFLoader(file_path)\n","        elif file_path.lower().endswith('.txt'):\n","            loader = TextLoader(file_path)\n","        else:\n","            raise ValueError(\"Unsupported file format. Please provide a .pdf or .txt file.\")\n","        return loader.load()\n","\n","    def classify_and_restore_file(self, file_path: str):\n","        \"\"\"\n","        Classifies and restores the content of the document from the given file path.\n","\n","        Args:\n","            file_path (str): The path to the file to be processed.\n","\n","        Returns:\n","            dict: A dictionary containing the file type and restored content.\n","        \"\"\"\n","        docs = self.load_documents(file_path)\n","        full_text = \" \".join([doc.page_content for doc in docs])\n","\n","        file_type = self.classification_chain.run({\"text\": full_text}).strip()\n","        restored_content = self.restoration_chain.run({\"text\": full_text})\n","\n","        return {\"file_type\": file_type, \"restored_content\": restored_content}\n","\n","    def classify_and_summarize_file(self, file_path: str):\n","        \"\"\"\n","        Classifies and summarizes the content of the document from the given file path.\n","\n","        Args:\n","            file_path (str): The path to the file to be processed.\n","\n","        Returns:\n","            dict: A dictionary containing the file type and summary.\n","        \"\"\"\n","        docs = self.load_documents(file_path)\n","        full_text = \" \".join([doc.page_content for doc in docs])\n","\n","        file_type = self.classification_chain.run({\"text\": full_text}).strip()\n","        summary = self.summary_chain.run({\"text\": full_text})\n","\n","        return {\"file_type\": file_type, \"summary\": summary}\n","\n","\n","# document_processor = DocumentProcessor()\n","# document_processor.classify_and_summarize_file(r\"C:\\Users\\ayush\\OneDrive\\Desktop\\Cm_work\\cm_om\\Amar_Singh_Thukral_S_O_Shri_Joumphi_vs_Sandeep_Chhatwal_S_O_Shri_Peshori_Lal_on_5_July_2004.PDF\")\n","\n","\n","def main():\n","    # Create an instance of DocumentProcessor\n","    document_processor = DocumentProcessor()\n","    \n","    # Path to the document you want to test\n","    file_path = r\"/kaggle/input/wp16200/WP_16200_2024_MEMO OF PETITION_2024-06-04_9481452.pdf\"  # Change this to the actual path of your file\n","\n","    # Call classify_and_restore_file method\n","    try:\n","        classification_and_restoration_result = document_processor.classify_and_restore_file(file_path)\n","        #print(\"Classification and Restoration Result:\")\n","        #print(\"File Type:\", classification_and_restoration_result['file_type'])            \n","        restored_content=classification_and_restoration_result['restored_content']\n","        print(\"Restored Content:\",restored_content)\n","    except Exception as e:\n","        print(f\"Error during classification and restoration: {e}\")\n","    return restored_content\n","\n","if __name__ == \"__main__\":\n","    restored_content=main()"]},{"cell_type":"code","execution_count":45,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-07-16T08:04:01.974775Z","iopub.status.busy":"2024-07-16T08:04:01.974074Z","iopub.status.idle":"2024-07-16T08:04:04.088966Z","shell.execute_reply":"2024-07-16T08:04:04.088205Z","shell.execute_reply.started":"2024-07-16T08:04:01.974738Z"},"trusted":true},"outputs":[],"source":["import PyPDF2\n","from langchain.text_splitter import RecursiveCharacterTextSplitter\n","from concurrent.futures import ThreadPoolExecutor\n","from tenacity import retry, stop_after_attempt, wait_exponential\n","import re\n","from langchain_groq import ChatGroq\n","import ast\n","import json\n","\n","\n","model_name = \"llama3-8b-8192\"\n","llm = ChatGroq(temperature=0, groq_api_key=\"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\", model=model_name)\n","\n","def extract_text_from_pdf(pdf_path):\n","    with open(pdf_path, 'rb') as file:\n","        reader = PyPDF2.PdfReader(file)\n","        text = \"\"\n","        for page in reader.pages:\n","            text += page.extract_text()\n","    return text\n","\n","def split_text(text, chunk_size=10000, chunk_overlap=50):\n","    text_splitter = RecursiveCharacterTextSplitter(\n","        chunk_size=chunk_size,\n","        chunk_overlap=chunk_overlap,\n","    )\n","    return text_splitter.split_text(text)\n","\n","@retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=4, max=10))\n","def extract_relations(chunk, llm):\n","    try:\n","        prompt = f\"\"\"\n","You are an expert in analyzing Indian writ case documents. Extract the following entities from the text:\n","\n","- CASE_NO\n","- COURT\n","- JUDGE\n","- DATE\n","- LAWYER\n","- PETITIONER\n","- RESPONDENT\n","- WITNESS\n","- WRIT_TYPE\n","- WRIT_SUBJECT\n","- RELIEF_SOUGHT\n","- MONETARY_AMOUNT\n","- GOVERNMENT_AGENCY\n","- RIGHTS_INVOLVED\n","- INTERIM_ORDER\n","- GROUNDS\n","- STATUTE\n","- PROVISION\n","- DOCUMENTS\n","\n","Afterwards, a detailed relation extraction on all entities recognised to output tuples as (entity,relation,entity).\n","\n","Identify the relationships between the extracted entity value and output a list of dictionaries containing head,relation,tail.Further head and tails will contain entity name and entity type each.\n","The tuples you generate will be used to develop a knowledge graph in accordance to the relations between entities later.\n","\n","Text: {chunk}\n","\n","OUTPUT STRUCTURE-\n","{{\"head\": {{\"name\": entity1_name, \"type\": ENTITY1_TYPE}}, \"relation\": RELATION_NAME, \"tail\": {{\"name\": entity2_name, \"type\": ENTITY2_TYPE}}}}\n","\n","INSTRUCTIONS-\n","-no tuples should be repeated.\n","-try to connect CASE_NO to all entities with relations that are good in a legal and professional manner  \n","-revise the tuples before outputand only keep important and clear tuples which have valid values\n","-entities which are none,na or not defined should not be included.\n","-remove double quotes from the entities and relations in tuples. (\"'COURT'\" -> 'COURT')\n","-entity \"type\" and \"relation\" values should be uppercase\n","\n","THE BELOW EXAMPLE is NOT TO BE INCLUDED IN YOUR RESPONSE AS IT JUST FOR REFERENCE AND LEARNING\n","AN EXAMPLE OUTPUT DICTIONARY OF A RANDOM WRIT FILE AND THE FORMAT OF THIS SHOULD BE IMITATED -\n","\n","[\n","{{\"head\"{{\"name\":\"High Court of Delhi\",\"type\":\"COURT\"}},\"relation\":\"HEARD_CASE\",\"tail\"{{\"name\":\"Writ Petition No. 12345/2023\",\"type\":\"CASE_NO\"}}}},{{\"head\"{{\"name\":\"Writ Petition No. 12345/2023\",\"type\":\"CASE_NO\"}},\"relation\":\"FILED_BY\",\"tail\"{{\"name\":\"Rajesh Kumar\",\"type\":\"PETITIONER\"}}}},{{\"head\"{{\"name\":\"Rajesh Kumar\",\"type\":\"PETITIONER\"}},\"relation\":\"REPRESENTED_BY\",\"tail\"{{\"name\":\"Adv. Suresh Gupta\",\"type\":\"LAWYER\"}}}},{{\"head\"{{\"name\":\"High Court of Delhi\",\"type\":\"COURT\"}},\"relation\":\"ISSUED_ORDER\",\"tail\"{{\"name\":\"Interim Order\",\"type\":\"ORDER\"}}}},{{\"head\"{{\"name\":\"Writ Petition No. 12345/2023\",\"type\":\"CASE_NO\"}},\"relation\":\"AGAINST\",\"tail\"{{\"name\":\"Ministry of Environment and Forests\",\"type\":\"GOVERNMENT_AGENCY\"}}}},{{\"head\"{{\"name\":\"Supreme Court of India\",\"type\":\"COURT\"}},\"relation\":\"ISSUED_JUDGMENT\",\"tail\"{{\"name\":\"Final Order\",\"type\":\"ORDER\"}}}},{{\"head\"{{\"name\":\"Writ Petition No. 67890/2022\",\"type\":\"CASE_NO\"}},\"relation\":\"FILED_BY\",\"tail\"{{\"name\":\"NGO Clean Air Initiative\",\"type\":\"PETITIONER\"}}}},{{\"head\"{{\"name\":\"NGO Clean Air Initiative\",\"type\":\"PETITIONER\"}},\"relation\":\"REPRESENTED_BY\",\"tail\"{{\"name\":\"Adv. Meera Shah\",\"type\":\"LAWYER\"}}}},{{\"head\"{{\"name\":\"Writ Petition No. 67890/2022\",\"type\":\"CASE_NO\"}},\"relation\":\"CHALLENGES\",\"tail\"{{\"name\":\"Air Quality Notification 2022\",\"type\":\"DOCUMENT\"}}}},{{\"head\"{{\"name\":\"Final Order\",\"type\":\"ORDER\"}},\"relation\":\"ISSUED_ON\",\"tail\"{{\"name\":\"2023-06-15\",\"type\":\"DATE\"}}}}\n","]\n","\n","-the ouput you produce should strictly just be a list of dictionary of tuples and no other text or explanation should be generated\n","   \"\"\"\n","        response = llm.predict(prompt)\n","        return response\n","    except Exception as e:\n","        print(f\"Error processing chunk: {e}\")\n","        raise\n","\n","def process_chunks_batch(chunks, llm, batch_size=1000):\n","    all_relations = []\n","    with ThreadPoolExecutor() as executor:\n","        for i in range(0, len(chunks), batch_size):\n","            batch = chunks[i:i+batch_size]\n","            results = list(executor.map(lambda chunk: extract_relations(chunk, llm), batch))\n","            all_relations.extend(results)\n","    return all_relations\n","\n","def combine_results(all_relations):\n","    return \"\\n\".join(all_relations)\n","\n","def extract_dictionaries(text):\n","    dictionaries = []\n","    current_dict = []\n","    in_dict = False\n","    bracket_depth = 0\n","\n","    i = 0\n","    while i < len(text):\n","        char = text[i]\n","\n","        if char == '{':\n","            bracket_depth += 1\n","            if bracket_depth == 1:\n","                current_dict = []\n","                in_dict = True\n","            current_dict.append(char)\n","\n","        elif char == '}':\n","            current_dict.append(char)\n","            bracket_depth -= 1\n","            if bracket_depth == 0 and in_dict:\n","                in_dict = False\n","                try:\n","                    parsed_dict = ast.literal_eval(\"\".join(current_dict))\n","                    if isinstance(parsed_dict, dict):\n","                        dictionaries.append(parsed_dict)\n","                except:\n","                    pass\n","                current_dict = []\n","\n","        elif in_dict:\n","            current_dict.append(char)\n","\n","        i += 1\n","\n","    return dictionaries\n","\n","#helper function for remove_duplicate_dicts\n","def dict_to_tuple(d):\n","    if isinstance(d, dict):\n","        return tuple((k, dict_to_tuple(v)) for k, v in sorted(d.items()))\n","    elif isinstance(d, list):\n","        return tuple(dict_to_tuple(v) for v in d)\n","    else:\n","        return d\n","\n","def remove_duplicate_dicts(dict_list):\n","    seen = set()\n","    unique_dicts = []\n","    for d in dict_list:\n","        # Convert the dictionary to a tuple representation\n","        dict_tuple = dict_to_tuple(d)\n","        if dict_tuple not in seen:\n","            seen.add(dict_tuple)\n","            unique_dicts.append(d)\n","    return unique_dicts\n","\n","\n","@retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=4, max=10))\n","def disambiguate_entities(tuples, llm):\n","    try:\n","        prompt = f\"\"\"\n","you are a legal expert who is very good at entity disambiguation.\n","You are provided with a dictionary of tuples representing entities and their relationships in the following format:\n","[\n","    \"head\": {{ \n","        \"name\": \"Entity Name\",\n","        \"type\": \"Entity Type\"\n","    }},\n","    \"relation\": \"Relationship Type\",\n","    \"tail\": {{\n","        \"name\": \"Entity Name\",\n","        \"type\": \"Entity Type\"\n","    }}\n","]\n","Your task is to manually perform entity disambiguation on data by handling entities that are similar or have minor spelling differences. Additionally, ensure that the entity name and entity type are not the same (e.g., \"name\": \"Government\" and \"type\": \"government\" should be corrected).\n","Identify entities with similar names or minor spelling differences (e.g., \"court\", \"Court\", \"court'\", \"COURT\") and combine them into a single entity.\n","Correct any entities where the name and type are identical or very similar, ensuring that the type accurately represents the entity category.\n","Return the corrected dictionary with disambiguated entities and relationships.\n","Example Input:\n","[\n","    {{\"head\": {{\"name\": \"High Court of Madhya Pradesh\", \"type\": \"court\"}}, \"relation\": \"has_registered\", \"tail\": {{\"name\": \"Cr. Appeal No. 262/2002\", \"type\": \"case_number\"}}}},\n","    {{\"head\": {{\"name\": \"High Court of Madhya Pradesh\", \"type\": \"court\"}}, \"relation\": \"decided\", \"tail\": {{\"name\": \"Cr. Appeal No. 262/2002\", \"type\": \"case_number\"}}}},\n","    {{\"head\": {{\"name\": \"High Court of MP\", \"type\": \"court\"}}, \"relation\": \"reviewed\", \"tail\": {{\"name\": \"Cr. Appeal No. 262/2002\", \"type\": \"case_number\"}}}},\n","    {{\"head\": {{\"name\": \"court\", \"type\": \"court\"}}, \"relation\": \"has_case\", \"tail\": {{\"name\": \"case_number\", \"type\": \"case_number\"}}}},\n","]\n","Expected Output:\n","[   {{\"head\": {{\"name\": \"High Court of Madhya Pradesh\", \"type\": \"court\"}}, \"relation\": \"has_registered\", \"tail\": {{\"name\": \"Cr. Appeal No. 262/2002\", \"type\": \"case_number\"}}}},\n","    {{\"head\": {{\"name\": \"High Court of Madhya Pradesh\", \"type\": \"court\"}}, \"relation\": \"decided\", \"tail\": {{\"name\": \"Cr. Appeal No. 262/2002\", \"type\": \"case_number\"}}}},\n","    {{\"head\": {{\"name\": \"High Court of Madhya Pradesh\", \"type\": \"court\"}}, \"relation\": \"reviewed\", \"tail\": {{\"name\": \"Cr. Appeal No. 262/2002\", \"type\": \"case_number\"}}}},\n","    {{\"head\": {{\"name\": \"High Court of Madhya Pradesh\", \"type\": \"court\"}}, \"relation\": \"has_case\", \"tail\": {{\"name\": \"Cr. Appeal No. 262/2002\", \"type\": \"case_number\"}}}},\n","]\n","Instructions:\n","try to retain the size of tuples and dont lose entities\n","Ensure for each entity, its name and type are not the same.\n","Return the disambiguated and corrected dictionary in the given format\n","your response should just contain the output data structure\n","\n","Actual input- {tuples} \n","        \"\"\"\n","        response = llm.predict(prompt)\n","        return response\n","    except Exception as e:\n","        print(f\"Error disambiguating entities: {e}\")\n","        raise\n","\n","def get_relation_tuples_from_pdf(pdf_path):\n","    #content = extract_text_from_pdf(pdf_path)\n","    chunks = split_text(restored_content)\n","    all_relations = process_chunks_batch(chunks, llm)\n","    final_result = combine_results(all_relations)\n","    dict_of_tuples = extract_dictionaries(final_result)\n","    unique_extracted_dictionaries = remove_duplicate_dicts(dict_of_tuples)\n","    #disambiguated_dict = disambiguate_entities(unique_extracted_dictionaries, llm)\n","    #extracted_dictionaries = extract_dictionaries(disambiguated_dict)\n","    return unique_extracted_dictionaries\n","\n","def main(pdf_path):\n","    tuples=get_relation_tuples_from_pdf(pdf_path)\n","    return tuples \n","\n","# Example usage:\n","pdf_path = '/kaggle/input/aabbcc/CRA_262_2002_FinalOrder_30-Jun-2021.pdf'\n","response = main(pdf_path)"]},{"cell_type":"code","execution_count":46,"metadata":{"execution":{"iopub.execute_input":"2024-07-16T08:04:07.444381Z","iopub.status.busy":"2024-07-16T08:04:07.444024Z","iopub.status.idle":"2024-07-16T08:04:07.449766Z","shell.execute_reply":"2024-07-16T08:04:07.448690Z","shell.execute_reply.started":"2024-07-16T08:04:07.444351Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["17 [{'head': {'name': 'High Court of Madhya Pradesh', 'type': 'COURT'}, 'relation': 'HEARD_CASE', 'tail': {'name': 'WRIT PETITION NO. & GP/024', 'type': 'CASE_NO'}}, {'head': {'name': 'WRIT PETITION NO. & GP/024', 'type': 'CASE_NO'}, 'relation': 'FILED_BY', 'tail': {'name': 'Sanjeev Kumar Sahu', 'type': 'PETITIONER'}}, {'head': {'name': 'Sanjeev Kumar Sahu', 'type': 'PETITIONER'}, 'relation': 'REPRESENTED_BY', 'tail': {'name': 'N/A', 'type': 'LAWYER'}}, {'head': {'name': 'High Court of Madhya Pradesh', 'type': 'COURT'}, 'relation': 'ISSUED_ORDER', 'tail': {'name': 'Interim Order', 'type': 'ORDER'}}, {'head': {'name': 'WRIT PETITION NO. & GP/024', 'type': 'CASE_NO'}, 'relation': 'AGAINST', 'tail': {'name': 'State of Madhya Pradesh', 'type': 'GOVERNMENT_AGENCY'}}, {'head': {'name': 'WRIT PETITION NO. & GP/024', 'type': 'CASE_NO'}, 'relation': 'AGAINST', 'tail': {'name': 'Madhya Pradesh Madhya Khetra Vidyut Vitran Company Limited', 'type': 'GOVERNMENT_AGENCY'}}, {'head': {'name': 'WRIT PETITION NO. & GP/024', 'type': 'CASE_NO'}, 'relation': 'AGAINST', 'tail': {'name': 'Collector, Raisen', 'type': 'GOVERNMENT_AGENCY'}}, {'head': {'name': 'WRIT PETITION NO. & GP/024', 'type': 'CASE_NO'}, 'relation': 'AGAINST', 'tail': {'name': 'Chief Engineer, Madhya Pradesh Madhya Khetra Vidyut Vitran Company Limited', 'type': 'GOVERNMENT_AGENCY'}}, {'head': {'name': 'WRIT PETITION NO. & GP/024', 'type': 'CASE_NO'}, 'relation': 'AGAINST', 'tail': {'name': 'Executive Engineer, Madhya Pradesh Madhya Khetra Vidyut Vitran Company Limited', 'type': 'GOVERNMENT_AGENCY'}}, {'head': {'name': 'WRIT PETITION NO. & GP/024', 'type': 'CASE_NO'}, 'relation': 'AGAINST', 'tail': {'name': 'Junior Engineer, Madhya Pradesh Madhya Khetra Vidyut Vitran Company Limited', 'type': 'GOVERNMENT_AGENCY'}}, {'head': {'name': 'WRIT PETITION NO. & GP/024', 'type': 'CASE_NO'}, 'relation': 'SEEKS', 'tail': {'name': 'Relief Sought', 'type': 'RELIEF_SOUGHT'}}, {'head': {'name': 'WRIT PETITION NO. & GP/024', 'type': 'CASE_NO'}, 'relation': 'SEEKS', 'tail': {'name': 'Rs. 5,00,000/-', 'type': 'MONETARY_AMOUNT'}}, {'head': {'name': 'WRIT PETITION NO. & GP/024', 'type': 'CASE_NO'}, 'relation': 'SEEKS', 'tail': {'name': 'Protection of life and business of the Petitioner', 'type': 'RIGHTS_INVOLVED'}}, {'head': {'name': 'WRIT PETITION NO. & GP/024', 'type': 'CASE_NO'}, 'relation': 'SEEKS', 'tail': {'name': 'Interim Order', 'type': 'INTERIM_ORDER'}}, {'head': {'name': 'WRIT PETITION NO. & GP/024', 'type': 'CASE_NO'}, 'relation': 'BASED_ON', 'tail': {'name': 'GROUNDS', 'type': 'GROUNDS'}}, {'head': {'name': 'WRIT PETITION NO. & GP/024', 'type': 'CASE_NO'}, 'relation': 'BASED_ON', 'tail': {'name': 'Acts Invoked', 'type': 'ACTS_INVOKED'}}, {'head': {'name': 'WRIT PETITION NO. & GP/024', 'type': 'CASE_NO'}, 'relation': 'RELATES_TO', 'tail': {'name': 'Document', 'type': 'DOCUMENTS'}}]\n"]}],"source":["print(len(response),response)"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-07-16T06:42:54.249443Z","iopub.status.busy":"2024-07-16T06:42:54.249111Z","iopub.status.idle":"2024-07-16T06:43:06.869735Z","shell.execute_reply":"2024-07-16T06:43:06.868684Z","shell.execute_reply.started":"2024-07-16T06:42:54.249412Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting neo4j\n","  Downloading neo4j-5.22.0-py3-none-any.whl.metadata (5.7 kB)\n","Requirement already satisfied: pytz in /opt/conda/lib/python3.10/site-packages (from neo4j) (2023.3.post1)\n","Downloading neo4j-5.22.0-py3-none-any.whl (293 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m293.5/293.5 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","\u001b[?25hInstalling collected packages: neo4j\n","Successfully installed neo4j-5.22.0\n"]}],"source":["!pip install neo4j\n"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-07-16T06:43:06.872192Z","iopub.status.busy":"2024-07-16T06:43:06.871418Z","iopub.status.idle":"2024-07-16T06:43:07.345169Z","shell.execute_reply":"2024-07-16T06:43:07.344154Z","shell.execute_reply.started":"2024-07-16T06:43:06.872154Z"},"trusted":true},"outputs":[],"source":["from neo4j import GraphDatabase\n","\n","# Replace these with your AuraDB credentials\n","uri = \"neo4j+s://6cb5ec24.databases.neo4j.io\"\n","user = \"neo4j\"\n","password = \"Ww3XWwg1qPUkKzeCoxmBGeM0Jw9pY3HZLQ2V7vzQwjA\"\n","\n"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-07-16T06:43:07.346942Z","iopub.status.busy":"2024-07-16T06:43:07.346310Z","iopub.status.idle":"2024-07-16T06:43:20.125045Z","shell.execute_reply":"2024-07-16T06:43:20.123913Z","shell.execute_reply.started":"2024-07-16T06:43:07.346915Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting py2neo\n","  Downloading py2neo-2021.2.4-py2.py3-none-any.whl.metadata (9.9 kB)\n","Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from py2neo) (2024.7.4)\n","Collecting interchange~=2021.0.4 (from py2neo)\n","  Downloading interchange-2021.0.4-py2.py3-none-any.whl.metadata (1.9 kB)\n","Collecting monotonic (from py2neo)\n","  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n","Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from py2neo) (24.1)\n","Collecting pansi>=2020.7.3 (from py2neo)\n","  Downloading pansi-2020.7.3-py2.py3-none-any.whl.metadata (6.0 kB)\n","Requirement already satisfied: pygments>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from py2neo) (2.17.2)\n","Requirement already satisfied: six>=1.15.0 in /opt/conda/lib/python3.10/site-packages (from py2neo) (1.16.0)\n","Requirement already satisfied: urllib3 in /opt/conda/lib/python3.10/site-packages (from py2neo) (1.26.18)\n","Requirement already satisfied: pytz in /opt/conda/lib/python3.10/site-packages (from interchange~=2021.0.4->py2neo) (2023.3.post1)\n","Downloading py2neo-2021.2.4-py2.py3-none-any.whl (177 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.2/177.2 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading interchange-2021.0.4-py2.py3-none-any.whl (28 kB)\n","Downloading pansi-2020.7.3-py2.py3-none-any.whl (10 kB)\n","Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n","Installing collected packages: monotonic, pansi, interchange, py2neo\n","Successfully installed interchange-2021.0.4 monotonic-1.6 pansi-2020.7.3 py2neo-2021.2.4\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["pip install py2neo"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-07-16T06:43:20.128339Z","iopub.status.busy":"2024-07-16T06:43:20.128005Z","iopub.status.idle":"2024-07-16T06:43:32.660772Z","shell.execute_reply":"2024-07-16T06:43:32.659625Z","shell.execute_reply.started":"2024-07-16T06:43:20.128310Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting pyvis\n","  Downloading pyvis-0.3.2-py3-none-any.whl.metadata (1.7 kB)\n","Requirement already satisfied: ipython>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from pyvis) (8.20.0)\n","Requirement already satisfied: jinja2>=2.9.6 in /opt/conda/lib/python3.10/site-packages (from pyvis) (3.1.2)\n","Collecting jsonpickle>=1.4.1 (from pyvis)\n","  Downloading jsonpickle-3.2.2-py3-none-any.whl.metadata (7.2 kB)\n","Requirement already satisfied: networkx>=1.11 in /opt/conda/lib/python3.10/site-packages (from pyvis) (3.2.1)\n","Requirement already satisfied: decorator in /opt/conda/lib/python3.10/site-packages (from ipython>=5.3.0->pyvis) (5.1.1)\n","Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.10/site-packages (from ipython>=5.3.0->pyvis) (0.19.1)\n","Requirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.10/site-packages (from ipython>=5.3.0->pyvis) (0.1.6)\n","Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /opt/conda/lib/python3.10/site-packages (from ipython>=5.3.0->pyvis) (3.0.42)\n","Requirement already satisfied: pygments>=2.4.0 in /opt/conda/lib/python3.10/site-packages (from ipython>=5.3.0->pyvis) (2.17.2)\n","Requirement already satisfied: stack-data in /opt/conda/lib/python3.10/site-packages (from ipython>=5.3.0->pyvis) (0.6.2)\n","Requirement already satisfied: traitlets>=5 in /opt/conda/lib/python3.10/site-packages (from ipython>=5.3.0->pyvis) (5.9.0)\n","Requirement already satisfied: exceptiongroup in /opt/conda/lib/python3.10/site-packages (from ipython>=5.3.0->pyvis) (1.2.0)\n","Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.10/site-packages (from ipython>=5.3.0->pyvis) (4.8.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2>=2.9.6->pyvis) (2.1.3)\n","Requirement already satisfied: parso<0.9.0,>=0.8.3 in /opt/conda/lib/python3.10/site-packages (from jedi>=0.16->ipython>=5.3.0->pyvis) (0.8.3)\n","Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.10/site-packages (from pexpect>4.3->ipython>=5.3.0->pyvis) (0.7.0)\n","Requirement already satisfied: wcwidth in /opt/conda/lib/python3.10/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=5.3.0->pyvis) (0.2.13)\n","Requirement already satisfied: executing>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=5.3.0->pyvis) (2.0.1)\n","Requirement already satisfied: asttokens>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=5.3.0->pyvis) (2.4.1)\n","Requirement already satisfied: pure-eval in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=5.3.0->pyvis) (0.2.2)\n","Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from asttokens>=2.1.0->stack-data->ipython>=5.3.0->pyvis) (1.16.0)\n","Downloading pyvis-0.3.2-py3-none-any.whl (756 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m756.0/756.0 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n","\u001b[?25hDownloading jsonpickle-3.2.2-py3-none-any.whl (41 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.8/41.8 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: jsonpickle, pyvis\n","Successfully installed jsonpickle-3.2.2 pyvis-0.3.2\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["pip install pyvis"]},{"cell_type":"code","execution_count":42,"metadata":{"execution":{"iopub.execute_input":"2024-07-16T07:52:26.202856Z","iopub.status.busy":"2024-07-16T07:52:26.202167Z","iopub.status.idle":"2024-07-16T07:52:58.326696Z","shell.execute_reply":"2024-07-16T07:52:58.325906Z","shell.execute_reply.started":"2024-07-16T07:52:26.202818Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_34/1735363727.py:36: DeprecationWarning: write_transaction has been renamed to execute_write\n","  session.write_transaction(\n"]}],"source":["from neo4j import GraphDatabase\n","import logging\n","\n","# Create a connection to AuraDB\n","def create_auradb_connection(uri, user, password):\n","    try:\n","        driver = GraphDatabase.driver(uri, auth=(user, password))\n","        return driver\n","    except Exception as e:\n","        logging.error(f\"Error creating AuraDB connection: {e}\")\n","        raise\n","\n","# Function to insert a tuple into AuraDB\n","def insert_tuple(tx, entity1_value, entity1_type, relation, entity2_value, entity2_type):\n","    try:\n","        query = f\"\"\"\n","                    MERGE (a:{entity1_type} {{name: $entity1_value}})\n","                    MERGE (b:{entity2_type} {{name: $entity2_value}})\n","                    MERGE (a)-[r:{relation}]->(b)\n","                \"\"\"\n","        tx.run(query, entity1_value=entity1_value, entity1_type=entity1_type, \n","               relation=relation, entity2_value=entity2_value, entity2_type=entity2_type)\n","    except Exception as e:\n","        logging.error(f\"Error inserting tuple: {e}\")\n","        raise\n","\n","# Process and insert dictionaries into AuraDB\n","def process_and_insert_dicts(uri, user, password, dicts):\n","    driver = create_auradb_connection(uri, user, password)\n","    try:\n","        with driver.session() as session:\n","            for d in dicts:\n","                head = d['head']\n","                tail = d['tail']\n","                try:\n","                    session.write_transaction(\n","                        insert_tuple,\n","                        head['name'], head['type'],\n","                        d['relation'],\n","                        tail['name'], tail['type']\n","                    )\n","                except Exception as e:\n","                    logging.error(f\"Error processing dictionary: {d}, Error: {e}\")\n","                    continue\n","    except Exception as e:\n","        logging.error(f\"Error during session operation: {e}\")\n","        raise\n","    finally:\n","        driver.close()\n","\n","# Process and insert dictionaries into AuraDB\n","process_and_insert_dicts(uri, user, password, response)\n"]},{"cell_type":"code","execution_count":43,"metadata":{"execution":{"iopub.execute_input":"2024-07-16T07:52:58.328457Z","iopub.status.busy":"2024-07-16T07:52:58.328128Z","iopub.status.idle":"2024-07-16T07:54:17.129232Z","shell.execute_reply":"2024-07-16T07:54:17.128277Z","shell.execute_reply.started":"2024-07-16T07:52:58.328412Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Warning: When  cdn_resources is 'local' jupyter notebook has issues displaying graphics on chrome/safari. Use cdn_resources='in_line' or cdn_resources='remote' if you have issues viewing graphics in a notebook.\n","knowledge_graph_not_restored.html\n"]},{"data":{"text/html":["\n","        <iframe\n","            width=\"100%\"\n","            height=\"1000px\"\n","            src=\"knowledge_graph_not_restored.html\"\n","            frameborder=\"0\"\n","            allowfullscreen\n","            \n","        ></iframe>\n","        "],"text/plain":["<IPython.lib.display.IFrame at 0x79c7f1a10340>"]},"execution_count":43,"metadata":{},"output_type":"execute_result"}],"source":["#RENDERING EXISTING KNOWLEDGE GRAPH FROM AURADB AS HTML(WITH COLOUR)\n","from py2neo import Graph\n","from pyvis.network import Network\n","import matplotlib.pyplot as plt\n","import matplotlib.colors as mcolors\n","import random\n","\n","\n","driver = GraphDatabase.driver(uri, auth=(user, password))\n","graph = Graph(uri, auth=(user, password))\n","\n","# Define a Cypher query to retrieve nodes and relationships\n","query = \"\"\"\n","MATCH (n)-[r]->(m)\n","RETURN n, r, m\n","LIMIT 400\n","\"\"\"\n","\n","result = graph.run(query)\n","\n","# Create a pyvis network\n","net = Network(height='1000px', width='100%', notebook=True, bgcolor='#FAF9F6', font_color='black')\n","\n","# Function to generate a random color\n","def random_color():\n","    return \"#{:06x}\".format(random.randint(0, 0xFFFFFF))\n","\n","# Dictionary to store colors for each label\n","label_colors = {}\n","\n","# Add nodes and edges from the query result\n","for record in result:\n","    n = record[\"n\"]\n","    r = record[\"r\"]\n","    m = record[\"m\"]\n","\n","    # Ensure names and labels are strings for serialization\n","    n_name = str(n[\"name\"])\n","    m_name = str(m[\"name\"])\n","    n_labels = list(n.labels)\n","    m_labels = list(m.labels)\n","    r_type = r.__class__.__name__\n","    # Assign colors to labels dynamically\n","    if n_labels:\n","        for label in n_labels:\n","            if label not in label_colors:\n","                label_colors[label] = random_color()\n","        n_color = label_colors[n_labels[0]]\n","    else:\n","        n_color = random_color()\n","\n","    if m_labels:\n","        for label in m_labels:\n","            if label not in label_colors:\n","                label_colors[label] = random_color()\n","        m_color = label_colors[m_labels[0]]\n","    else:\n","        m_color = random_color()\n","\n","    net.add_node(n_name, label=n_name, title=\", \".join(n_labels), color=n_color)\n","    net.add_node(m_name, label=m_name, title=\", \".join(m_labels), color=m_color)\n","    net.add_edge(n_name, m_name,title=r_type, color='#FFD700')\n","\n","# Generate network with options\n","net.show_buttons(filter_=['physics'])\n","net.show('knowledge_graph_not_restored.html')\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":5331662,"sourceId":8856743,"sourceType":"datasetVersion"},{"datasetId":5335573,"sourceId":8864572,"sourceType":"datasetVersion"},{"datasetId":5359890,"sourceId":8913365,"sourceType":"datasetVersion"},{"datasetId":5360178,"sourceId":8913734,"sourceType":"datasetVersion"},{"datasetId":5371847,"sourceId":8929876,"sourceType":"datasetVersion"},{"datasetId":5372286,"sourceId":8930462,"sourceType":"datasetVersion"},{"datasetId":5372407,"sourceId":8930620,"sourceType":"datasetVersion"},{"datasetId":5395655,"sourceId":8964085,"sourceType":"datasetVersion"},{"datasetId":5396418,"sourceId":8965064,"sourceType":"datasetVersion"}],"dockerImageVersionId":30747,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
