{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8856743,"sourceType":"datasetVersion","datasetId":5331662},{"sourceId":8864572,"sourceType":"datasetVersion","datasetId":5335573},{"sourceId":8913365,"sourceType":"datasetVersion","datasetId":5359890},{"sourceId":8913734,"sourceType":"datasetVersion","datasetId":5360178},{"sourceId":8929876,"sourceType":"datasetVersion","datasetId":5371847},{"sourceId":8930462,"sourceType":"datasetVersion","datasetId":5372286},{"sourceId":8930620,"sourceType":"datasetVersion","datasetId":5372407},{"sourceId":8964085,"sourceType":"datasetVersion","datasetId":5395655},{"sourceId":8965064,"sourceType":"datasetVersion","datasetId":5396418}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install langchain_community","metadata":{"execution":{"iopub.status.busy":"2024-07-16T06:42:05.647151Z","iopub.execute_input":"2024-07-16T06:42:05.647935Z","iopub.status.idle":"2024-07-16T06:42:24.052559Z","shell.execute_reply.started":"2024-07-16T06:42:05.647904Z","shell.execute_reply":"2024-07-16T06:42:24.051464Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting langchain_community\n  Downloading langchain_community-0.2.7-py3-none-any.whl.metadata (2.5 kB)\nRequirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (6.0.1)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (2.0.25)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (3.9.1)\nRequirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (0.6.7)\nCollecting langchain<0.3.0,>=0.2.7 (from langchain_community)\n  Downloading langchain-0.2.8-py3-none-any.whl.metadata (6.9 kB)\nCollecting langchain-core<0.3.0,>=0.2.12 (from langchain_community)\n  Downloading langchain_core-0.2.19-py3-none-any.whl.metadata (6.0 kB)\nCollecting langsmith<0.2.0,>=0.1.0 (from langchain_community)\n  Downloading langsmith-0.1.86-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: numpy<2,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (1.26.4)\nRequirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (2.32.3)\nRequirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (8.2.3)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.3)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.21.3)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\nCollecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain<0.3.0,>=0.2.7->langchain_community)\n  Downloading langchain_text_splitters-0.2.2-py3-none-any.whl.metadata (2.1 kB)\nRequirement already satisfied: pydantic<3,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain<0.3.0,>=0.2.7->langchain_community) (2.5.3)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.12->langchain_community) (1.33)\nCollecting packaging<25,>=23.2 (from langchain-core<0.3.0,>=0.2.12->langchain_community)\n  Downloading packaging-24.1-py3-none-any.whl.metadata (3.2 kB)\nCollecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.0->langchain_community)\n  Downloading orjson-3.10.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain_community) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain_community) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain_community) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain_community) (2024.7.4)\nRequirement already satisfied: typing-extensions>=4.6.0 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain_community) (4.9.0)\nRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.0.3)\nRequirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.12->langchain_community) (2.4)\nRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.7->langchain_community) (0.6.0)\nRequirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.7->langchain_community) (2.14.6)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\nDownloading langchain_community-0.2.7-py3-none-any.whl (2.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading langchain-0.2.8-py3-none-any.whl (987 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m987.6/987.6 kB\u001b[0m \u001b[31m45.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langchain_core-0.2.19-py3-none-any.whl (366 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m366.5/366.5 kB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langsmith-0.1.86-py3-none-any.whl (129 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.4/129.4 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langchain_text_splitters-0.2.2-py3-none-any.whl (25 kB)\nDownloading orjson-3.10.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading packaging-24.1-py3-none-any.whl (53 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: packaging, orjson, langsmith, langchain-core, langchain-text-splitters, langchain, langchain_community\n  Attempting uninstall: packaging\n    Found existing installation: packaging 21.3\n    Uninstalling packaging-21.3:\n      Successfully uninstalled packaging-21.3\n  Attempting uninstall: orjson\n    Found existing installation: orjson 3.9.10\n    Uninstalling orjson-3.9.10:\n      Successfully uninstalled orjson-3.9.10\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 24.6.1 requires cubinlinker, which is not installed.\ncudf 24.6.1 requires cupy-cuda11x>=12.0.0, which is not installed.\ncudf 24.6.1 requires ptxcompiler, which is not installed.\ncuml 24.6.1 requires cupy-cuda11x>=12.0.0, which is not installed.\ndask-cudf 24.6.1 requires cupy-cuda11x>=12.0.0, which is not installed.\nkeras-cv 0.9.0 requires keras-core, which is not installed.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.8 which is incompatible.\napache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.4 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 16.1.0 which is incompatible.\ncudf 24.6.1 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.5.0 which is incompatible.\ndistributed 2024.5.1 requires dask==2024.5.1, but you have dask 2024.7.0 which is incompatible.\ngoogle-cloud-bigquery 2.34.4 requires packaging<22.0dev,>=14.3, but you have packaging 24.1 which is incompatible.\njupyterlab 4.2.3 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\njupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\nlibpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nmomepy 0.7.2 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\nosmnx 1.9.3 requires shapely>=2.0, but you have shapely 1.8.5.post1 which is incompatible.\npointpats 2.5.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\nrapids-dask-dependency 24.6.0a0 requires dask==2024.5.1, but you have dask 2024.7.0 which is incompatible.\nspaghetti 1.7.6 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nspopt 0.6.1 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\ntensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.4.1 which is incompatible.\nydata-profiling 4.6.4 requires numpy<1.26,>=1.16.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed langchain-0.2.8 langchain-core-0.2.19 langchain-text-splitters-0.2.2 langchain_community-0.2.7 langsmith-0.1.86 orjson-3.10.6 packaging-24.1\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install PyPDF2 langchain langchain_groq","metadata":{"execution":{"iopub.status.busy":"2024-07-16T06:42:24.054648Z","iopub.execute_input":"2024-07-16T06:42:24.054933Z","iopub.status.idle":"2024-07-16T06:42:37.164056Z","shell.execute_reply.started":"2024-07-16T06:42:24.054909Z","shell.execute_reply":"2024-07-16T06:42:37.163151Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Collecting PyPDF2\n  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\nRequirement already satisfied: langchain in /opt/conda/lib/python3.10/site-packages (0.2.8)\nCollecting langchain_groq\n  Downloading langchain_groq-0.1.6-py3-none-any.whl.metadata (2.8 kB)\nRequirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (6.0.1)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.0.25)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (3.9.1)\nRequirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (4.0.3)\nRequirement already satisfied: langchain-core<0.3.0,>=0.2.19 in /opt/conda/lib/python3.10/site-packages (from langchain) (0.2.19)\nRequirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (0.2.2)\nRequirement already satisfied: langsmith<0.2.0,>=0.1.17 in /opt/conda/lib/python3.10/site-packages (from langchain) (0.1.86)\nRequirement already satisfied: numpy<2,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain) (1.26.4)\nRequirement already satisfied: pydantic<3,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.5.3)\nRequirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.32.3)\nRequirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (8.2.3)\nCollecting groq<1,>=0.4.1 (from langchain_groq)\n  Downloading groq-0.9.0-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\nRequirement already satisfied: anyio<5,>=3.5.0 in /opt/conda/lib/python3.10/site-packages (from groq<1,>=0.4.1->langchain_groq) (4.2.0)\nRequirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from groq<1,>=0.4.1->langchain_groq) (1.9.0)\nRequirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from groq<1,>=0.4.1->langchain_groq) (0.27.0)\nRequirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from groq<1,>=0.4.1->langchain_groq) (1.3.0)\nRequirement already satisfied: typing-extensions<5,>=4.7 in /opt/conda/lib/python3.10/site-packages (from groq<1,>=0.4.1->langchain_groq) (4.9.0)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.19->langchain) (1.33)\nRequirement already satisfied: packaging<25,>=23.2 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.19->langchain) (24.1)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.6)\nRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (0.6.0)\nRequirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (2.14.6)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2024.7.4)\nRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->groq<1,>=0.4.1->langchain_groq) (1.2.0)\nRequirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq) (1.0.5)\nRequirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq) (0.14.0)\nRequirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.19->langchain) (2.4)\nDownloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading langchain_groq-0.1.6-py3-none-any.whl (14 kB)\nDownloading groq-0.9.0-py3-none-any.whl (103 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.5/103.5 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: PyPDF2, groq, langchain_groq\nSuccessfully installed PyPDF2-3.0.1 groq-0.9.0 langchain_groq-0.1.6\n","output_type":"stream"}]},{"cell_type":"code","source":"!  pip install PyPDF2","metadata":{"execution":{"iopub.status.busy":"2024-07-16T06:42:37.165597Z","iopub.execute_input":"2024-07-16T06:42:37.165977Z","iopub.status.idle":"2024-07-16T06:42:49.151488Z","shell.execute_reply.started":"2024-07-16T06:42:37.165939Z","shell.execute_reply":"2024-07-16T06:42:49.150341Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Requirement already satisfied: PyPDF2 in /opt/conda/lib/python3.10/site-packages (3.0.1)\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install  langchain langchain_community langchain_groq PyPDF2 concurrent","metadata":{"execution":{"iopub.status.busy":"2024-07-16T06:42:49.154019Z","iopub.execute_input":"2024-07-16T06:42:49.154326Z","iopub.status.idle":"2024-07-16T06:42:51.661341Z","shell.execute_reply.started":"2024-07-16T06:42:49.154299Z","shell.execute_reply":"2024-07-16T06:42:51.660461Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Requirement already satisfied: langchain in /opt/conda/lib/python3.10/site-packages (0.2.8)\nRequirement already satisfied: langchain_community in /opt/conda/lib/python3.10/site-packages (0.2.7)\nRequirement already satisfied: langchain_groq in /opt/conda/lib/python3.10/site-packages (0.1.6)\nRequirement already satisfied: PyPDF2 in /opt/conda/lib/python3.10/site-packages (3.0.1)\n\u001b[31mERROR: Could not find a version that satisfies the requirement concurrent (from versions: none)\u001b[0m\u001b[31m\n\u001b[0m\u001b[31mERROR: No matching distribution found for concurrent\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"!pip install PyMuPDF","metadata":{"execution":{"iopub.status.busy":"2024-07-16T07:28:28.509691Z","iopub.execute_input":"2024-07-16T07:28:28.510324Z","iopub.status.idle":"2024-07-16T07:28:42.525572Z","shell.execute_reply.started":"2024-07-16T07:28:28.510292Z","shell.execute_reply":"2024-07-16T07:28:42.524570Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Collecting PyMuPDF\n  Downloading PyMuPDF-1.24.7-cp310-none-manylinux2014_x86_64.whl.metadata (3.4 kB)\nCollecting PyMuPDFb==1.24.6 (from PyMuPDF)\n  Downloading PyMuPDFb-1.24.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.4 kB)\nDownloading PyMuPDF-1.24.7-cp310-none-manylinux2014_x86_64.whl (3.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading PyMuPDFb-1.24.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (15.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.7/15.7 MB\u001b[0m \u001b[31m77.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: PyMuPDFb, PyMuPDF\nSuccessfully installed PyMuPDF-1.24.7 PyMuPDFb-1.24.6\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport tempfile\nfrom pydantic import BaseModel\nfrom langchain_community.document_loaders import TextLoader, PyMuPDFLoader\nfrom langchain.prompts import PromptTemplate\nfrom langchain.chains import LLMChain\nfrom langchain_groq import ChatGroq\n\n# class DocumentClassificationResponse(BaseModel):\n#     \"\"\"\n#     A Pydantic model to structure the response for document classification and restoration.\n#     \"\"\"\n#     file_type: str\n#     restored_content: str\n\n# class DocumentSummarizationResponse(BaseModel):\n#     \"\"\"\n#     A Pydantic model to structure the response for document summarization.\n#     \"\"\"\n#     file_type: str\n#     summary: str\n\nclass DocumentProcessor:\n    \"\"\"\n    A class to handle document loading, classification, restoration, and summarization using language models.\n    \"\"\"\n\n    def __init__(self):\n        \"\"\"\n        Initializes the DocumentProcessor with necessary configurations.\n        \"\"\"\n        self.llm = ChatGroq(model_name=\"Llama3-8b-8192\", api_key=\"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\")\n        self.classification_template = PromptTemplate.from_template(self._get_classification_template())\n        self.restoration_template = PromptTemplate.from_template(self._get_restoration_template())\n        self.summary_template = PromptTemplate.from_template(self._get_summary_template())\n        self.classification_chain = LLMChain(llm=self.llm, prompt=self.classification_template)\n        self.restoration_chain = LLMChain(llm=self.llm, prompt=self.restoration_template)\n        self.summary_chain = LLMChain(llm=self.llm, prompt=self.summary_template)\n\n    @staticmethod\n    def _get_classification_template():\n        \"\"\"\n        Returns the classification template for the LLM.\n\n        Returns:\n            str: The template string for document classification.\n        \"\"\"\n        return \"\"\"<s>[INST] The following is an article:\n        {text}\n        Based on this, please classify the document into one of the following categories: Civil, Criminal, Writ.\n        You can use below paragraph for classification of the document: \n        \"Civil cases involve disputes between individuals, organizations, or the government, seeking legal remedies like compensation for issues such as contract disputes, torts, family law matters, property disputes, and employment issues.\n        Criminal cases are offenses against the state or public, with the government prosecuting individuals or entities for crimes like felonies (murder, robbery), misdemeanors (petty theft), and infractions (traffic violations), aiming to punish and deter criminal behavior. \n        Writ cases involve judicial orders to correct legal errors or enforce rights, with common writs including habeas corpus (ensuring lawful detention), mandamus (ordering a public official to perform a duty), prohibition (stopping a lower court from exceeding its jurisdiction), certiorari (reviewing a lower court's decision), and quo warranto (challenging the right to hold public office).\"\n        Answer with the category only and nothing else:  [/INST] </s>\"\"\"\n\n    @staticmethod\n    def _get_restoration_template():\n        \"\"\"\n        Returns the restoration template for the LLM.\n\n        Returns:\n            str: The template string for document restoration.\n        \"\"\"\n        return \"\"\"<s>[INST] The following is an article:\n        {text}\n        Based on this, please restore the content of the document by removing anomalous characters and gibberish to produce comprehensible content with proper grammar. \n        Answer:  [/INST] </s>\"\"\"\n\n    @staticmethod\n    def _get_summary_template():\n        \"\"\"\n        Returns the summary template for the LLM.\n\n        Returns:\n            str: The template string for document summarization.\n        \"\"\"\n        return \"\"\"<s>[INST] The following is an article:\n        {text}\n        Based on this, please provide a summary. \n        Answer:  [/INST] </s>\"\"\"\n\n    def load_documents(self, file_path):\n        \"\"\"\n        Loads documents from the given file path.\n\n        Args:\n            file_path (str): The path to the file to be loaded.\n\n        Returns:\n            list: A list of document objects.\n\n        Raises:\n            ValueError: If the file format is unsupported.\n        \"\"\"\n        if file_path.lower().endswith('.pdf'):\n            loader = PyMuPDFLoader(file_path)\n        elif file_path.lower().endswith('.txt'):\n            loader = TextLoader(file_path)\n        else:\n            raise ValueError(\"Unsupported file format. Please provide a .pdf or .txt file.\")\n        return loader.load()\n\n    def classify_and_restore_file(self, file_path: str):\n        \"\"\"\n        Classifies and restores the content of the document from the given file path.\n\n        Args:\n            file_path (str): The path to the file to be processed.\n\n        Returns:\n            dict: A dictionary containing the file type and restored content.\n        \"\"\"\n        docs = self.load_documents(file_path)\n        full_text = \" \".join([doc.page_content for doc in docs])\n\n        file_type = self.classification_chain.run({\"text\": full_text}).strip()\n        restored_content = self.restoration_chain.run({\"text\": full_text})\n\n        return {\"file_type\": file_type, \"restored_content\": restored_content}\n\n    def classify_and_summarize_file(self, file_path: str):\n        \"\"\"\n        Classifies and summarizes the content of the document from the given file path.\n\n        Args:\n            file_path (str): The path to the file to be processed.\n\n        Returns:\n            dict: A dictionary containing the file type and summary.\n        \"\"\"\n        docs = self.load_documents(file_path)\n        full_text = \" \".join([doc.page_content for doc in docs])\n\n        file_type = self.classification_chain.run({\"text\": full_text}).strip()\n        summary = self.summary_chain.run({\"text\": full_text})\n\n        return {\"file_type\": file_type, \"summary\": summary}\n\n\n# document_processor = DocumentProcessor()\n# document_processor.classify_and_summarize_file(r\"C:\\Users\\ayush\\OneDrive\\Desktop\\Cm_work\\cm_om\\Amar_Singh_Thukral_S_O_Shri_Joumphi_vs_Sandeep_Chhatwal_S_O_Shri_Peshori_Lal_on_5_July_2004.PDF\")\n\n\ndef main():\n    # Create an instance of DocumentProcessor\n    document_processor = DocumentProcessor()\n    \n    # Path to the document you want to test\n    file_path = r\"/kaggle/input/criminal-6072/CRA_6072_2024_MEMO OF APPEAL_2024-05-16_9402965.pdf\"  # Change this to the actual path of your file\n\n    # Call classify_and_restore_file method\n    try:\n        classification_and_restoration_result = document_processor.classify_and_restore_file(file_path)\n        #print(\"Classification and Restoration Result:\")\n        #print(\"File Type:\", classification_and_restoration_result['file_type'])            \n        restored_content=classification_and_restoration_result['restored_content']\n        print(\"Restored Content:\",restored_content)\n    except Exception as e:\n        print(f\"Error during classification and restoration: {e}\")\n    return restored_content\n\nif __name__ == \"__main__\":\n    restored_content=main()","metadata":{"execution":{"iopub.status.busy":"2024-07-16T07:33:32.814941Z","iopub.execute_input":"2024-07-16T07:33:32.815335Z","iopub.status.idle":"2024-07-16T07:33:34.802567Z","shell.execute_reply.started":"2024-07-16T07:33:32.815306Z","shell.execute_reply":"2024-07-16T07:33:34.801719Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"Restored Content: Here is the restored content of the document:\n\n**IN THE HIGH COURT OF MADHYA PRADESH**\n\n**PRINCIPAL SEAT AT JABALPUR**\n\n**Criminal Appeal No. 672/2024**\n\n**APPELLANT**\n\n**Sohel Kapoor**\n\n**(In Jail)**\n\n**S/o Shri Saleem Kapoor, aged about 29 years, Occupation Labour, R/o Ward no.13, Near CMO Bangla, Patel Ward Multai, District Betul (M.P.)**\n\n**RESPONDENTS**\n\n**1. The State of Madhya Pradesh**\n**Through Police Station Kotwali-Betul, District Betul (M.P.)**\n**2. Victim-A**\n\n**APPEAL UNDER SECTION 14(A) OF SC/ST (PREVENTION OF ATROCITIES) ACT 1989 FOR GRANT OF BAIL**\n\n**Whether any bail application is pending before or already disposed of?**\n\n**Institution No. Date of Institution Result**\n\n* Hon'ble Supreme Court of India: Nil\n* Hon'ble High Court: Nil\n* Sub Court: Nil\n* B.A. No. 14-05-2024: Rejected\n* Ordinate to High Court: 200304/2024\n\n**PARTICULARS OF CRIME**\n\n**Crime No. 151/2024**\n**Police Station— Kotwali Betul, District Betul (M.P.)**\n**Offence: U/s 294, 323, 506, 34, 342, 327, 365, 368, 325 of IPC & U/s 3(1)(e), 3(1)(@), 3(1)(()), 3(2) (v) & 3(2)(va), of SC/ST Act**\n\n**PARTICULARS OF IMPUGNED ORDER**\n\n**Date of Order: 14-05-2024**\n**Date of Arrest: 14-02-2024**\n\n**THE APPELLANT NAMED ABOVE BEGS TO SUBMIT AS UNDER:**\n\n1. That, this is the appellant's FIRST CRIMINAL APPEAL for grant of bail against the order dated 14-05-2024.\n\n**PARTICULARS OF EARLIER APPLICATIONS**\n\n* Nil\n\n**PARTICULARS OF EARLIER IDENTICAL/SIMILAR MATTERS**\n\n* Nil\n\n**FACTS OF THE CASE IN BRIEF:**\n\nThat, on 15.11.2023, in the afternoon, Rinkesh Chauhan came to the complainant's house and said he had to go to Betul. The complainant took his motor vehicle and went away sitting on a bicycle. On the way, Nitin also sat with them, whom they deceived and took to Chant @ Sohrab's house. Then Chant said they would have to pay the rent of the shop. When the complainant refused to pay the money, Chant, Rinkesh, Sohail, and other three-four of their associates abused him, stripped him of his clothes, tied his hands and legs with a rope in a naked state, and hung him upside down from an iron pipe on the roof with the help of a spade. He was beaten badly with a belt, and a video of him was made, and he was threatened to be killed. Due to fear, the complainant did not tell anyone about the incident or write a report. On 13.02.2024, when the video of the assault went viral, then the complainant told the entire incident to his brother, and they lodged a report against the accused persons. Thereafter, Police Station Kotwali Betul dated 13.02.2024 registered the offences U/s 294, 323, 506, 34, 342, 327, 365, 368, 325 of IPC and U/s 3(1)(e), 3(1)(@), 3(1)(()), 3(2) (v) & 3(2)(va), of SC/ST Act against the applicant and other accused persons vide Crime No. 151/2024.\n\n**GROUNDS:**\n\n1. That, the present appellant is innocent and has been falsely implicated in the case, and the police have already completed the investigation and charged sheet has been filed.\n2. That, on the basis of false facts and circumstances, the offences registered against the applicant.\n3. That, nothing is seized from the possession of the applicant.\n4. That, on the basis of the memorandum, the applicant made an accused in this case.\n5. That, about one year's delay in registration of FIR.\n6. That, the co-accused have been granted bail by the learned Trial Court, as well as accused Sheikh Afjal has been granted bail by this Hon'ble Court. Copies of the order of co-accused are filed herewith as Annexure A-2.\n\n**PRAYER**\n\nIt is, therefore, prayed that this Hon'ble Court may kindly be pleased to order that the accused be enlarged on bail, in the interest of justice.\n\n**ADVOCATE FOR THE APPELLANT**\n\n(P. S. Chauhan)\n**Date: 16-05-2024**\n","output_type":"stream"}]},{"cell_type":"code","source":"import PyPDF2\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom concurrent.futures import ThreadPoolExecutor\nfrom tenacity import retry, stop_after_attempt, wait_exponential\nimport re\nfrom langchain_groq import ChatGroq\nimport ast\nimport json\n\n\nmodel_name = \"llama3-8b-8192\"\nllm = ChatGroq(temperature=0, groq_api_key=\"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\", model=model_name)\n\ndef extract_text_from_pdf(pdf_path):\n    with open(pdf_path, 'rb') as file:\n        reader = PyPDF2.PdfReader(file)\n        text = \"\"\n        for page in reader.pages:\n            text += page.extract_text()\n    return text\n\ndef split_text(text, chunk_size=10000, chunk_overlap=50):\n    text_splitter = RecursiveCharacterTextSplitter(\n        chunk_size=chunk_size,\n        chunk_overlap=chunk_overlap,\n    )\n    return text_splitter.split_text(text)\n\n@retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=4, max=10))\ndef extract_relations(chunk, llm):\n    try:\n        prompt = f\"\"\"\nYou are an expert in analyzing Indian criminal case documents. Extract the following entities from the text:\n\n- CASE_NO\n- COURT\n- JUDGE\n- DATE\n- LAWYER\n- PETITIONER\n- RESPONDENT\n- WITNESS\n- VICTIM\n- CRIME\n- SENTENCE\n- CHARGE\n- EVIDENCE\n- POLICE\n- FIR_NUMBER\n- BAIL\n- CRIME_SCENE\n- FORENSIC_EVIDENCE\n- JUDGEMENT\n\nAfterwards, a detailed relation extraction on all entities recognised to output tuples as (entity,relation,entity).\n\nIdentify the relationships between the extracted entity value and output a list of dictionaries containing head,relation,tail.Further head and tails will contain entity name and entity type each.\nThe tuples you generate will be used to develop a knowledge graph in accordance to the relations between entities later.\n\nText: {chunk}\n\nOUTPUT STRUCTURE-\n{{\"head\": {{\"name\": entity1_name, \"type\": ENTITY1_TYPE}}, \"relation\": RELATION_NAME, \"tail\": {{\"name\": entity2_name, \"type\": ENTITY2_TYPE}}}}\n\nINSTRUCTIONS-\n-no tuples should be repeated.\n-try to connect CASE_NO to all entities with relations that are good in a legal and professional manner  \n-revise the tuples before outputand only keep important and clear tuples which have valid values\n-entities which are none,na or not defined should not be included.\n-remove double quotes from the entities and relations in tuples. (\"'COURT'\" -> 'COURT')\n-entity \"type\" and \"relation\" values should be uppercase\n\nTHE BELOW EXAMPLE is NOT TO BE INCLUDED IN YOUR RESPONSE AS IT JUST FOR REFERENCE AND LEARNING\nAN EXAMPLE OUTPUT DICTIONARY OF A RANDOM CRIMINAL FILE AND THE FORMAT OF THIS SHOULD BE IMITATED -\n\n[\n{{HEAD: {{NAME: \"Case No. 1234/2024\", TYPE: \"CASE_NO\"}}, RELATION: \"BELONGS_TO\", TAIL: {{NAME: \"Judge XYZ\", TYPE: \"JUDGE\"}}}},\n{{HEAD: {{NAME: \"District Court, ABC City\", TYPE: \"COURT\"}}, RELATION: \"HAS_JUDGE\", TAIL: {{NAME: \"Judge XYZ\", TYPE: \"JUDGE\"}}}},\n{{HEAD: {{NAME: \"Judge XYZ\", TYPE: \"JUDGE\"}}, RELATION: \"PRESIDED_OVER\", TAIL: {{NAME: \"Case No. 1234/2024\", TYPE: \"CASE_NO\"}}}},\n{{HEAD: {{NAME: \"Case No. 1234/2024\", TYPE: \"CASE_NO\"}}, RELATION: \"HEARD_ON\", TAIL: {{NAME: \"2024-07-16\", TYPE: \"DATE\"}}}},\n{{HEAD: {{NAME: \"Lawyer ABC\", TYPE: \"LAWYER\"}}, RELATION: \"REPRESENTS\", TAIL: {{NAME: \"Accused XYZ\", TYPE: \"RESPONDENT\"}}}},\n{{HEAD: {{NAME: \"Victim PQR\", TYPE: \"VICTIM\"}}, RELATION: \"AFFECTED_BY\", TAIL: {{NAME: \"Crime ABC\", TYPE: \"CRIME\"}}}},\n{{HEAD: {{NAME: \"Crime ABC\", TYPE: \"CRIME\"}}, RELATION: \"COMMITTED_IN\", TAIL: {{NAME: \"Location XYZ\", TYPE: \"CRIME_SCENE\"}}}},\n{{HEAD: {{NAME: \"Accused XYZ\", TYPE: \"RESPONDENT\"}}, RELATION: \"SENTENCED_TO\", TAIL: {{NAME: \"10 years imprisonment\", TYPE: \"SENTENCE\"}}}},\n{{HEAD: {{NAME: \"Accused XYZ\", TYPE: \"RESPONDENT\"}}, RELATION: \"CHARGED_WITH\", TAIL: {{NAME: \"Murder\", TYPE: \"CHARGE\"}}}},\n{{HEAD: {{NAME: \"Forensic Report ABC\", TYPE: \"EVIDENCE\"}}, RELATION: \"RELATED_TO\", TAIL: {{NAME: \"Crime ABC\", TYPE: \"CRIME\"}}}},\n{{HEAD: {{NAME: \"Officer XYZ\", TYPE: \"POLICE\"}}, RELATION: \"INVESTIGATED\", TAIL: {{NAME: \"Case No. 1234/2024\", TYPE: \"CASE_NO\"}}}},\n{{HEAD: {{NAME: \"FIR No. 5678\", TYPE: \"FIR_NUMBER\"}}, RELATION: \"FILED_FOR\", TAIL: {{NAME: \"Crime ABC\", TYPE: \"CRIME\"}}}},\n{{HEAD: {{NAME: \"Accused XYZ\", TYPE: \"RESPONDENT\"}}, RELATION: \"GRANTED_BAIL\", TAIL: {{NAME: \"Bail Granted\", TYPE: \"BAIL_STATUS\"}}}},\n{{HEAD: {{NAME: \"Witness ABC\", TYPE: \"WITNESS\"}}, RELATION: \"TESTIFIED_IN\", TAIL: {{NAME: \"Case No. 1234/2024\", TYPE: \"CASE_NO\"}}}},\n{{HEAD: {{NAME: \"Location XYZ\", TYPE: \"CRIME_SCENE\"}}, RELATION: \"RELATED_TO\", TAIL: {{NAME: \"Crime ABC\", TYPE: \"CRIME\"}}}},\n{{HEAD: {{NAME: \"Blood Sample XYZ\", TYPE: \"FORENSIC_EVIDENCE\"}}, RELATION: \"COLLECTED_FROM\", TAIL: {{NAME: \"Crime Scene ABC\", TYPE: \"CRIME_SCENE\"}}}},\n{{HEAD: {{NAME: \"Judge XYZ\", TYPE: \"JUDGE\"}}, RELATION: \"ISSUED\", TAIL: {{NAME: \"Guilty Verdict\", TYPE: \"JUDGMENT\"}}}}\n]\n\n-the ouput you produce should strictly just be a list of dictionary of tuples and no other text or explanation should be generated\n    \"\"\"\n        response = llm.predict(prompt)\n        return response\n    except Exception as e:\n        print(f\"Error processing chunk: {e}\")\n        raise\n\ndef process_chunks_batch(chunks, llm, batch_size=1000):\n    all_relations = []\n    with ThreadPoolExecutor() as executor:\n        for i in range(0, len(chunks), batch_size):\n            batch = chunks[i:i+batch_size]\n            results = list(executor.map(lambda chunk: extract_relations(chunk, llm), batch))\n            all_relations.extend(results)\n    return all_relations\n\ndef combine_results(all_relations):\n    return \"\\n\".join(all_relations)\n\ndef extract_dictionaries(text):\n    dictionaries = []\n    current_dict = []\n    in_dict = False\n    bracket_depth = 0\n\n    i = 0\n    while i < len(text):\n        char = text[i]\n\n        if char == '{':\n            bracket_depth += 1\n            if bracket_depth == 1:\n                current_dict = []\n                in_dict = True\n            current_dict.append(char)\n\n        elif char == '}':\n            current_dict.append(char)\n            bracket_depth -= 1\n            if bracket_depth == 0 and in_dict:\n                in_dict = False\n                try:\n                    parsed_dict = ast.literal_eval(\"\".join(current_dict))\n                    if isinstance(parsed_dict, dict):\n                        dictionaries.append(parsed_dict)\n                except:\n                    pass\n                current_dict = []\n\n        elif in_dict:\n            current_dict.append(char)\n\n        i += 1\n\n    return dictionaries\n\n#helper function for remove_duplicate_dicts\ndef dict_to_tuple(d):\n    if isinstance(d, dict):\n        return tuple((k, dict_to_tuple(v)) for k, v in sorted(d.items()))\n    elif isinstance(d, list):\n        return tuple(dict_to_tuple(v) for v in d)\n    else:\n        return d\n\ndef remove_duplicate_dicts(dict_list):\n    seen = set()\n    unique_dicts = []\n    for d in dict_list:\n        # Convert the dictionary to a tuple representation\n        dict_tuple = dict_to_tuple(d)\n        if dict_tuple not in seen:\n            seen.add(dict_tuple)\n            unique_dicts.append(d)\n    return unique_dicts\n\n\n@retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=4, max=10))\ndef disambiguate_entities(tuples, llm):\n    try:\n        prompt = f\"\"\"\nyou are a legal expert who is very good at entity disambiguation.\nYou are provided with a dictionary of tuples representing entities and their relationships in the following format:\n[\n    \"head\": {{ \n        \"name\": \"Entity Name\",\n        \"type\": \"Entity Type\"\n    }},\n    \"relation\": \"Relationship Type\",\n    \"tail\": {{\n        \"name\": \"Entity Name\",\n        \"type\": \"Entity Type\"\n    }}\n]\nYour task is to manually perform entity disambiguation on data by handling entities that are similar or have minor spelling differences. Additionally, ensure that the entity name and entity type are not the same (e.g., \"name\": \"Government\" and \"type\": \"government\" should be corrected).\nIdentify entities with similar names or minor spelling differences (e.g., \"court\", \"Court\", \"court'\", \"COURT\") and combine them into a single entity.\nCorrect any entities where the name and type are identical or very similar, ensuring that the type accurately represents the entity category.\nReturn the corrected dictionary with disambiguated entities and relationships.\nExample Input:\n[\n    {{\"head\": {{\"name\": \"High Court of Madhya Pradesh\", \"type\": \"court\"}}, \"relation\": \"has_registered\", \"tail\": {{\"name\": \"Cr. Appeal No. 262/2002\", \"type\": \"case_number\"}}}},\n    {{\"head\": {{\"name\": \"High Court of Madhya Pradesh\", \"type\": \"court\"}}, \"relation\": \"decided\", \"tail\": {{\"name\": \"Cr. Appeal No. 262/2002\", \"type\": \"case_number\"}}}},\n    {{\"head\": {{\"name\": \"High Court of MP\", \"type\": \"court\"}}, \"relation\": \"reviewed\", \"tail\": {{\"name\": \"Cr. Appeal No. 262/2002\", \"type\": \"case_number\"}}}},\n    {{\"head\": {{\"name\": \"court\", \"type\": \"court\"}}, \"relation\": \"has_case\", \"tail\": {{\"name\": \"case_number\", \"type\": \"case_number\"}}}},\n]\nExpected Output:\n[   {{\"head\": {{\"name\": \"High Court of Madhya Pradesh\", \"type\": \"court\"}}, \"relation\": \"has_registered\", \"tail\": {{\"name\": \"Cr. Appeal No. 262/2002\", \"type\": \"case_number\"}}}},\n    {{\"head\": {{\"name\": \"High Court of Madhya Pradesh\", \"type\": \"court\"}}, \"relation\": \"decided\", \"tail\": {{\"name\": \"Cr. Appeal No. 262/2002\", \"type\": \"case_number\"}}}},\n    {{\"head\": {{\"name\": \"High Court of Madhya Pradesh\", \"type\": \"court\"}}, \"relation\": \"reviewed\", \"tail\": {{\"name\": \"Cr. Appeal No. 262/2002\", \"type\": \"case_number\"}}}},\n    {{\"head\": {{\"name\": \"High Court of Madhya Pradesh\", \"type\": \"court\"}}, \"relation\": \"has_case\", \"tail\": {{\"name\": \"Cr. Appeal No. 262/2002\", \"type\": \"case_number\"}}}},\n]\nInstructions:\ntry to retain the size of tuples and dont lose entities\nEnsure for each entity, its name and type are not the same.\nReturn the disambiguated and corrected dictionary in the given format\nyour response should just contain the output data structure\n\nActual input- {tuples} \n        \"\"\"\n        response = llm.predict(prompt)\n        return response\n    except Exception as e:\n        print(f\"Error disambiguating entities: {e}\")\n        raise\n\ndef get_relation_tuples_from_pdf(pdf_path):\n    content = extract_text_from_pdf(pdf_path)\n    chunks = split_text(content)\n    all_relations = process_chunks_batch(chunks, llm)\n    final_result = combine_results(all_relations)\n    dict_of_tuples = extract_dictionaries(final_result)\n    unique_extracted_dictionaries = remove_duplicate_dicts(dict_of_tuples)\n    #disambiguated_dict = disambiguate_entities(unique_extracted_dictionaries, llm)\n    #extracted_dictionaries = extract_dictionaries(disambiguated_dict)\n    return unique_extracted_dictionaries\n\ndef main(pdf_path):\n    tuples=get_relation_tuples_from_pdf(pdf_path)\n    return tuples \n\n# Example usage:\npdf_path = '/kaggle/input/aabbcc/CRA_262_2002_FinalOrder_30-Jun-2021.pdf'\nresponse = main(pdf_path)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-16T07:51:05.028918Z","iopub.execute_input":"2024-07-16T07:51:05.029273Z","iopub.status.idle":"2024-07-16T07:51:07.747584Z","shell.execute_reply.started":"2024-07-16T07:51:05.029244Z","shell.execute_reply":"2024-07-16T07:51:07.746828Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"print(len(response),response)","metadata":{"execution":{"iopub.status.busy":"2024-07-16T07:51:09.068313Z","iopub.execute_input":"2024-07-16T07:51:09.068700Z","iopub.status.idle":"2024-07-16T07:51:09.074331Z","shell.execute_reply.started":"2024-07-16T07:51:09.068670Z","shell.execute_reply":"2024-07-16T07:51:09.073335Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stdout","text":"43 [{'head': {'name': 'Cr. Appeal No.262/2002', 'type': 'CASE_NO'}, 'relation': 'BELONGS_TO', 'tail': {'name': 'HIGH COURT OF MADHYA PRADESH, PRINCIPAL SEAT', 'type': 'COURT'}}, {'head': {'name': 'HIGH COURT OF MADHYA PRADESH, PRINCIPAL SEAT', 'type': 'COURT'}, 'relation': 'HEARD_BY', 'tail': {'name': 'Justice Prakash Shrivastava', 'type': 'JUDGE'}}, {'head': {'name': 'Justice Prakash Shrivastava', 'type': 'JUDGE'}, 'relation': 'DELIVERED_JUDGMENT', 'tail': {'name': 'Cr. Appeal No.262/2002', 'type': 'CASE_NO'}}, {'head': {'name': 'Karan Singh', 'type': 'PETITIONER'}, 'relation': 'FILED_APPEAL', 'tail': {'name': 'Cr. Appeal No.262/2002', 'type': 'CASE_NO'}}, {'head': {'name': 'State of M.P.', 'type': 'RESPONDENT'}, 'relation': 'RESPONDED_TO', 'tail': {'name': 'Cr. Appeal No.262/2002', 'type': 'CASE_NO'}}, {'head': {'name': 'Justice Prakash Shrivastava', 'type': 'JUDGE'}, 'relation': 'DELIVERED_OPINION', 'tail': {'name': 'Cr. Appeal No.262/2002', 'type': 'CASE_NO'}}, {'head': {'name': 'Karan Singh', 'type': 'PETITIONER'}, 'relation': 'CHALLENGED_SENTENCE', 'tail': {'name': 'Life Imprisonment', 'type': 'SENTENCE'}}, {'head': {'name': 'Life Imprisonment', 'type': 'SENTENCE'}, 'relation': 'AWARDED_TO', 'tail': {'name': 'Karan Singh', 'type': 'PETITIONER'}}, {'head': {'name': 'Karan Singh', 'type': 'PETITIONER'}, 'relation': 'ARGUED_BY', 'tail': {'name': 'Shri Ahadulla Usmani', 'type': 'LAWYER'}}, {'head': {'name': 'State of M.P.', 'type': 'RESPONDENT'}, 'relation': 'ARGUED_BY', 'tail': {'name': 'Shri S.K. Kashyap', 'type': 'LAWYER'}}, {'head': {'name': 'Akeela Bai', 'type': 'WITNESS'}, 'relation': 'TESTIFIED_IN', 'tail': {'name': 'Cr. Appeal No.262/2002', 'type': 'CASE_NO'}}, {'head': {'name': 'Sarju Bai', 'type': 'WITNESS'}, 'relation': 'TESTIFIED_IN', 'tail': {'name': 'Cr. Appeal No.262/2002', 'type': 'CASE_NO'}}, {'head': {'name': 'Babu', 'type': 'WITNESS'}, 'relation': 'TESTIFIED_IN', 'tail': {'name': 'Cr. Appeal No.262/2002', 'type': 'CASE_NO'}}, {'head': {'name': 'Kamla Bai', 'type': 'VICTIM'}, 'relation': 'AFFECTED_BY', 'tail': {'name': 'Cr. Appeal No.262/2002', 'type': 'CASE_NO'}}, {'head': {'name': 'Cr. Appeal No.262/2002', 'type': 'CASE_NO'}, 'relation': 'RELATED_TO', 'tail': {'name': 'Crime under Section 363, 366, 376 and 376 of the IPC', 'type': 'CRIME'}}, {'head': {'name': 'Crime under Section 363, 366, 376 and 376 of the IPC', 'type': 'CRIME'}, 'relation': 'COMMITTED_IN', 'tail': {'name': 'Buddleia Forest', 'type': 'CRIME_SCENE'}}, {'head': {'name': 'Buddleia Forest', 'type': 'CRIME_SCENE'}, 'relation': 'RELATED_TO', 'tail': {'name': 'Cr. Appeal No.262/2002', 'type': 'CASE_NO'}}, {'head': {'name': 'Cr. Appeal No.262/2002', 'type': 'CASE_NO'}, 'relation': 'HEARD_ON', 'tail': {'name': '30.06.2021', 'type': 'DATE'}}, {'head': {'name': 'Justice Prakash Shrivastava', 'type': 'JUDGE'}, 'relation': 'PRESIDED_OVER', 'tail': {'name': 'Cr. Appeal No.262/2002', 'type': 'CASE_NO'}}, {'head': {'name': 'Cr. Appeal No.262/2002', 'type': 'CASE_NO'}, 'relation': 'SENTENCED_TO', 'tail': {'name': 'Life Imprisonment', 'type': 'SENTENCE'}}, {'head': {'name': 'Karan Singh', 'type': 'PETITIONER'}, 'relation': 'CHALLENGED_SENTENCE', 'tail': {'name': 'Cr. Appeal No.262/2002', 'type': 'CASE_NO'}}, {'head': {'name': 'Cr. Appeal No.262/2002', 'type': 'CASE_NO'}, 'relation': 'RELATED_TO', 'tail': {'name': 'Section 53 of the IPC', 'type': 'LAW'}}, {'head': {'name': 'Section 53 of the IPC', 'type': 'LAW'}, 'relation': 'DEFINED', 'tail': {'name': 'Life Imprisonment', 'type': 'SENTENCE'}}, {'head': {'name': 'Cr. Appeal No.262/2002', 'type': 'CASE_NO'}, 'relation': 'RELATED_TO', 'tail': {'name': 'Section 45 of the IPC', 'type': 'LAW'}}, {'head': {'name': 'Section 45 of the IPC', 'type': 'LAW'}, 'relation': 'DEFINED', 'tail': {'name': 'Life', 'type': 'TERM'}}, {'head': {'name': 'Cr. Appeal No.262/2002', 'type': 'CASE_NO'}, 'relation': 'RELATED_TO', 'tail': {'name': 'Gopal Vinayak Godse vs. State of Maharashtra and others', 'type': 'CASE'}}, {'head': {'name': 'Gopal Vinayak Godse vs. State of Maharashtra and others', 'type': 'CASE'}, 'relation': 'CITED', 'tail': {'name': 'Cr. Appeal No.262/2002', 'type': 'CASE_NO'}}, {'head': {'name': 'Cr. Appeal No.262/2002', 'type': 'CASE_NO'}, 'relation': 'RELATED_TO', 'tail': {'name': 'Maru Ram vs. Union of India and others', 'type': 'CASE'}}, {'head': {'name': 'Maru Ram vs. Union of India and others', 'type': 'CASE'}, 'relation': 'CITED', 'tail': {'name': 'Cr. Appeal No.262/2002', 'type': 'CASE_NO'}}, {'head': {'name': 'Cr. Appeal No.262/2002', 'type': 'CASE_NO'}, 'relation': 'RELATED_TO', 'tail': {'name': 'State of M.P. vs. Ratan Singh', 'type': 'CASE'}}, {'head': {'name': 'State of M.P. vs. Ratan Singh', 'type': 'CASE'}, 'relation': 'CITED', 'tail': {'name': 'Cr. Appeal No.262/2002', 'type': 'CASE_NO'}}, {'head': {'name': 'Cr. Appeal No.262/2002', 'type': 'CASE_NO'}, 'relation': 'RELATED_TO', 'tail': {'name': 'Supreme Court', 'type': 'COURT'}}, {'head': {'name': 'Supreme Court', 'type': 'COURT'}, 'relation': 'HEARD', 'tail': {'name': 'Cr. Appeal No.262/2002', 'type': 'CASE_NO'}}, {'head': {'name': 'Prakash Shrivasta', 'type': 'JUDGE'}, 'relation': 'HEARD', 'tail': {'name': 'Cr. Appeal No.262/2002', 'type': 'CASE_NO'}}, {'head': {'name': 'Akhil Kumar Shrivasta', 'type': 'JUDGE'}, 'relation': 'HEARD', 'tail': {'name': 'Cr. Appeal No.262/2002', 'type': 'CASE_NO'}}, {'head': {'name': 'Cr. Appeal No.262/2002', 'type': 'CASE_NO'}, 'relation': 'DISPOSED_OF', 'tail': {'name': 'Prakash Shrivasta', 'type': 'JUDGE'}}, {'head': {'name': 'Prakash Shrivasta', 'type': 'JUDGE'}, 'relation': 'DIRECTED', 'tail': {'name': 'State Government', 'type': 'GOVERNMENT'}}, {'head': {'name': 'State Government', 'type': 'GOVERNMENT'}, 'relation': 'TO_CONSIDER', 'tail': {'name': 'Release of Appellant', 'type': 'RELEASE'}}, {'head': {'name': 'Release of Appellant', 'type': 'RELEASE'}, 'relation': 'IN_ACCORDANCE_WITH', 'tail': {'name': 'Law', 'type': 'LAW'}}, {'head': {'name': 'Law', 'type': 'LAW'}, 'relation': 'APPLIES_TO', 'tail': {'name': 'Cr. Appeal No.262/2002', 'type': 'CASE_NO'}}, {'head': {'name': 'Cr. Appeal No.262/2002', 'type': 'CASE_NO'}, 'relation': 'RELATED_TO', 'tail': {'name': 'Union of India vs. V. Sriharan @ Murugan and others', 'type': 'CASE'}}, {'head': {'name': 'Union of India vs. V. Sriharan @ Murugan and others', 'type': 'CASE'}, 'relation': 'HELD', 'tail': {'name': 'Power of Remission', 'type': 'POWER'}}, {'head': {'name': 'Power of Remission', 'type': 'POWER'}, 'relation': 'VESTS_WITH', 'tail': {'name': 'State Government', 'type': 'GOVERNMENT'}}]\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install neo4j\n","metadata":{"execution":{"iopub.status.busy":"2024-07-16T06:42:54.249111Z","iopub.execute_input":"2024-07-16T06:42:54.249443Z","iopub.status.idle":"2024-07-16T06:43:06.869735Z","shell.execute_reply.started":"2024-07-16T06:42:54.249412Z","shell.execute_reply":"2024-07-16T06:43:06.868684Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Collecting neo4j\n  Downloading neo4j-5.22.0-py3-none-any.whl.metadata (5.7 kB)\nRequirement already satisfied: pytz in /opt/conda/lib/python3.10/site-packages (from neo4j) (2023.3.post1)\nDownloading neo4j-5.22.0-py3-none-any.whl (293 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m293.5/293.5 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: neo4j\nSuccessfully installed neo4j-5.22.0\n","output_type":"stream"}]},{"cell_type":"code","source":"from neo4j import GraphDatabase\n\n# Replace these with your AuraDB credentials\nuri = \"neo4j+s://6cb5ec24.databases.neo4j.io\"\nuser = \"neo4j\"\npassword = \"Ww3XWwg1qPUkKzeCoxmBGeM0Jw9pY3HZLQ2V7vzQwjA\"\n\n","metadata":{"execution":{"iopub.status.busy":"2024-07-16T06:43:06.871418Z","iopub.execute_input":"2024-07-16T06:43:06.872192Z","iopub.status.idle":"2024-07-16T06:43:07.345169Z","shell.execute_reply.started":"2024-07-16T06:43:06.872154Z","shell.execute_reply":"2024-07-16T06:43:07.344154Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"pip install py2neo","metadata":{"execution":{"iopub.status.busy":"2024-07-16T06:43:07.346310Z","iopub.execute_input":"2024-07-16T06:43:07.346942Z","iopub.status.idle":"2024-07-16T06:43:20.125045Z","shell.execute_reply.started":"2024-07-16T06:43:07.346915Z","shell.execute_reply":"2024-07-16T06:43:20.123913Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Collecting py2neo\n  Downloading py2neo-2021.2.4-py2.py3-none-any.whl.metadata (9.9 kB)\nRequirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from py2neo) (2024.7.4)\nCollecting interchange~=2021.0.4 (from py2neo)\n  Downloading interchange-2021.0.4-py2.py3-none-any.whl.metadata (1.9 kB)\nCollecting monotonic (from py2neo)\n  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from py2neo) (24.1)\nCollecting pansi>=2020.7.3 (from py2neo)\n  Downloading pansi-2020.7.3-py2.py3-none-any.whl.metadata (6.0 kB)\nRequirement already satisfied: pygments>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from py2neo) (2.17.2)\nRequirement already satisfied: six>=1.15.0 in /opt/conda/lib/python3.10/site-packages (from py2neo) (1.16.0)\nRequirement already satisfied: urllib3 in /opt/conda/lib/python3.10/site-packages (from py2neo) (1.26.18)\nRequirement already satisfied: pytz in /opt/conda/lib/python3.10/site-packages (from interchange~=2021.0.4->py2neo) (2023.3.post1)\nDownloading py2neo-2021.2.4-py2.py3-none-any.whl (177 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.2/177.2 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading interchange-2021.0.4-py2.py3-none-any.whl (28 kB)\nDownloading pansi-2020.7.3-py2.py3-none-any.whl (10 kB)\nDownloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\nInstalling collected packages: monotonic, pansi, interchange, py2neo\nSuccessfully installed interchange-2021.0.4 monotonic-1.6 pansi-2020.7.3 py2neo-2021.2.4\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"pip install pyvis","metadata":{"execution":{"iopub.status.busy":"2024-07-16T06:43:20.128005Z","iopub.execute_input":"2024-07-16T06:43:20.128339Z","iopub.status.idle":"2024-07-16T06:43:32.660772Z","shell.execute_reply.started":"2024-07-16T06:43:20.128310Z","shell.execute_reply":"2024-07-16T06:43:32.659625Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Collecting pyvis\n  Downloading pyvis-0.3.2-py3-none-any.whl.metadata (1.7 kB)\nRequirement already satisfied: ipython>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from pyvis) (8.20.0)\nRequirement already satisfied: jinja2>=2.9.6 in /opt/conda/lib/python3.10/site-packages (from pyvis) (3.1.2)\nCollecting jsonpickle>=1.4.1 (from pyvis)\n  Downloading jsonpickle-3.2.2-py3-none-any.whl.metadata (7.2 kB)\nRequirement already satisfied: networkx>=1.11 in /opt/conda/lib/python3.10/site-packages (from pyvis) (3.2.1)\nRequirement already satisfied: decorator in /opt/conda/lib/python3.10/site-packages (from ipython>=5.3.0->pyvis) (5.1.1)\nRequirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.10/site-packages (from ipython>=5.3.0->pyvis) (0.19.1)\nRequirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.10/site-packages (from ipython>=5.3.0->pyvis) (0.1.6)\nRequirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /opt/conda/lib/python3.10/site-packages (from ipython>=5.3.0->pyvis) (3.0.42)\nRequirement already satisfied: pygments>=2.4.0 in /opt/conda/lib/python3.10/site-packages (from ipython>=5.3.0->pyvis) (2.17.2)\nRequirement already satisfied: stack-data in /opt/conda/lib/python3.10/site-packages (from ipython>=5.3.0->pyvis) (0.6.2)\nRequirement already satisfied: traitlets>=5 in /opt/conda/lib/python3.10/site-packages (from ipython>=5.3.0->pyvis) (5.9.0)\nRequirement already satisfied: exceptiongroup in /opt/conda/lib/python3.10/site-packages (from ipython>=5.3.0->pyvis) (1.2.0)\nRequirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.10/site-packages (from ipython>=5.3.0->pyvis) (4.8.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2>=2.9.6->pyvis) (2.1.3)\nRequirement already satisfied: parso<0.9.0,>=0.8.3 in /opt/conda/lib/python3.10/site-packages (from jedi>=0.16->ipython>=5.3.0->pyvis) (0.8.3)\nRequirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.10/site-packages (from pexpect>4.3->ipython>=5.3.0->pyvis) (0.7.0)\nRequirement already satisfied: wcwidth in /opt/conda/lib/python3.10/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=5.3.0->pyvis) (0.2.13)\nRequirement already satisfied: executing>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=5.3.0->pyvis) (2.0.1)\nRequirement already satisfied: asttokens>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=5.3.0->pyvis) (2.4.1)\nRequirement already satisfied: pure-eval in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=5.3.0->pyvis) (0.2.2)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from asttokens>=2.1.0->stack-data->ipython>=5.3.0->pyvis) (1.16.0)\nDownloading pyvis-0.3.2-py3-none-any.whl (756 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m756.0/756.0 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading jsonpickle-3.2.2-py3-none-any.whl (41 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.8/41.8 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: jsonpickle, pyvis\nSuccessfully installed jsonpickle-3.2.2 pyvis-0.3.2\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"from neo4j import GraphDatabase\nimport logging\n\n# Create a connection to AuraDB\ndef create_auradb_connection(uri, user, password):\n    try:\n        driver = GraphDatabase.driver(uri, auth=(user, password))\n        return driver\n    except Exception as e:\n        logging.error(f\"Error creating AuraDB connection: {e}\")\n        raise\n\n# Function to insert a tuple into AuraDB\ndef insert_tuple(tx, entity1_value, entity1_type, relation, entity2_value, entity2_type):\n    try:\n        query = f\"\"\"\n                    MERGE (a:{entity1_type} {{name: $entity1_value}})\n                    MERGE (b:{entity2_type} {{name: $entity2_value}})\n                    MERGE (a)-[r:{relation}]->(b)\n                \"\"\"\n        tx.run(query, entity1_value=entity1_value, entity1_type=entity1_type, \n               relation=relation, entity2_value=entity2_value, entity2_type=entity2_type)\n    except Exception as e:\n        logging.error(f\"Error inserting tuple: {e}\")\n        raise\n\n# Process and insert dictionaries into AuraDB\ndef process_and_insert_dicts(uri, user, password, dicts):\n    driver = create_auradb_connection(uri, user, password)\n    try:\n        with driver.session() as session:\n            for d in dicts:\n                head = d['head']\n                tail = d['tail']\n                try:\n                    session.write_transaction(\n                        insert_tuple,\n                        head['name'], head['type'],\n                        d['relation'],\n                        tail['name'], tail['type']\n                    )\n                except Exception as e:\n                    logging.error(f\"Error processing dictionary: {d}, Error: {e}\")\n                    continue\n    except Exception as e:\n        logging.error(f\"Error during session operation: {e}\")\n        raise\n    finally:\n        driver.close()\n\n# Process and insert dictionaries into AuraDB\nprocess_and_insert_dicts(uri, user, password, response)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-16T07:52:26.202167Z","iopub.execute_input":"2024-07-16T07:52:26.202856Z","iopub.status.idle":"2024-07-16T07:52:58.326696Z","shell.execute_reply.started":"2024-07-16T07:52:26.202818Z","shell.execute_reply":"2024-07-16T07:52:58.325906Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_34/1735363727.py:36: DeprecationWarning: write_transaction has been renamed to execute_write\n  session.write_transaction(\n","output_type":"stream"}]},{"cell_type":"code","source":"#RENDERING EXISTING KNOWLEDGE GRAPH FROM AURADB AS HTML(WITH COLOUR)\nfrom py2neo import Graph\nfrom pyvis.network import Network\nimport matplotlib.pyplot as plt\nimport matplotlib.colors as mcolors\nimport random\n\n\ndriver = GraphDatabase.driver(uri, auth=(user, password))\ngraph = Graph(uri, auth=(user, password))\n\n# Define a Cypher query to retrieve nodes and relationships\nquery = \"\"\"\nMATCH (n)-[r]->(m)\nRETURN n, r, m\nLIMIT 400\n\"\"\"\n\nresult = graph.run(query)\n\n# Create a pyvis network\nnet = Network(height='1000px', width='100%', notebook=True, bgcolor='#FAF9F6', font_color='black')\n\n# Function to generate a random color\ndef random_color():\n    return \"#{:06x}\".format(random.randint(0, 0xFFFFFF))\n\n# Dictionary to store colors for each label\nlabel_colors = {}\n\n# Add nodes and edges from the query result\nfor record in result:\n    n = record[\"n\"]\n    r = record[\"r\"]\n    m = record[\"m\"]\n\n    # Ensure names and labels are strings for serialization\n    n_name = str(n[\"name\"])\n    m_name = str(m[\"name\"])\n    n_labels = list(n.labels)\n    m_labels = list(m.labels)\n    r_type = r.__class__.__name__\n    # Assign colors to labels dynamically\n    if n_labels:\n        for label in n_labels:\n            if label not in label_colors:\n                label_colors[label] = random_color()\n        n_color = label_colors[n_labels[0]]\n    else:\n        n_color = random_color()\n\n    if m_labels:\n        for label in m_labels:\n            if label not in label_colors:\n                label_colors[label] = random_color()\n        m_color = label_colors[m_labels[0]]\n    else:\n        m_color = random_color()\n\n    net.add_node(n_name, label=n_name, title=\", \".join(n_labels), color=n_color)\n    net.add_node(m_name, label=m_name, title=\", \".join(m_labels), color=m_color)\n    net.add_edge(n_name, m_name,title=r_type, color='#FFD700')\n\n# Generate network with options\nnet.show_buttons(filter_=['physics'])\nnet.show('knowledge_graph_not_restored.html')\n","metadata":{"execution":{"iopub.status.busy":"2024-07-16T07:52:58.328128Z","iopub.execute_input":"2024-07-16T07:52:58.328457Z","iopub.status.idle":"2024-07-16T07:54:17.129232Z","shell.execute_reply.started":"2024-07-16T07:52:58.328412Z","shell.execute_reply":"2024-07-16T07:54:17.128277Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stdout","text":"Warning: When  cdn_resources is 'local' jupyter notebook has issues displaying graphics on chrome/safari. Use cdn_resources='in_line' or cdn_resources='remote' if you have issues viewing graphics in a notebook.\nknowledge_graph_not_restored.html\n","output_type":"stream"},{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"<IPython.lib.display.IFrame at 0x79c7f1a10340>","text/html":"\n        <iframe\n            width=\"100%\"\n            height=\"1000px\"\n            src=\"knowledge_graph_not_restored.html\"\n            frameborder=\"0\"\n            allowfullscreen\n            \n        ></iframe>\n        "},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}